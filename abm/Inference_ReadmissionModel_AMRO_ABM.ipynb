{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from utils_local.misc import amro2title, amro2cute\n",
    "import matplotlib.ticker as mtick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\"):\n",
    "    amro_prev_df = pd.read_csv(path_to_prev)\n",
    "    gammas       = amro_prev_df[amro_prev_df.amro==amro][[\"prevalence_mean1\", \"prevalence_mean2\", \"prevalence_mean3\"]].values / 100\n",
    "    return np.squeeze(gammas)\n",
    "\n",
    "def simulate_abm(f, f0, g, θ, model_settings):\n",
    "    dates_simulation      = model_settings[\"dates_simulation\"]\n",
    "    x                     = f0(θ)\n",
    "    observations          = np.full((len(dates_simulation), model_settings[\"k\"], model_settings[\"m\"]), np.nan)\n",
    "    observations[0, :, :] = g(0, x, θ)\n",
    "\n",
    "    for t, date in enumerate(dates_simulation[1:]):\n",
    "        x                       = f(t, x, θ)\n",
    "        observations[t+1, :, :] = g(t, x, θ)\n",
    "    return observations\n",
    "\n",
    "def create_obs_infer(obs_sim, idx_infer, dates, model_settings, resample=\"W-Sun\"):\n",
    "    # obs_sim \\in R^{[k x T x m]} as required by pompjax\n",
    "    infer_df = pd.DataFrame(index=dates)\n",
    "    for i in range(model_settings[\"k\"]) :\n",
    "        infer_df['y'+str(i+1)]   = obs_sim[i, :, idx_infer]\n",
    "        infer_df['oev'+str(i+1)] = 1 +(0.2 * infer_df['y'+str(i+1)].values)**2\n",
    "    infer_df                     = infer_df.resample(resample).sum()\n",
    "    infer_df.index.values[-1]    = model_settings[\"dates\"][-1]\n",
    "    return infer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/data/long_files_8_25_2021/patient_movement_2022-Nov.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dates_simulation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-02-28\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m movement_df                  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_db_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlong_files_8_25_2021\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatient_movement_2022-Nov.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrn\u001b[39m\u001b[38;5;124m\"\u001b[39m], keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m movement_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mward_total\u001b[39m\u001b[38;5;124m\"\u001b[39m]    \u001b[38;5;241m=\u001b[39m movement_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m movement_df                  \u001b[38;5;241m=\u001b[39m movement_df[movement_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(dates_simulation)]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/data/long_files_8_25_2021/patient_movement_2022-Nov.csv'"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "ward2buildingid        =  {row.ward: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient:\n",
    "    susceptible = 0\n",
    "    colonized   = 1\n",
    "\n",
    "class Observed:\n",
    "    no  = 0\n",
    "    yes = 1\n",
    "\n",
    "def amr_abm_readmissions(t, agents_state, gamma, beta, alpha, movement, ward2size, model_settings):\n",
    "    \"\"\" Agent based model tracking colonized and susceptible patients with pre-defined movement patterns.\n",
    "\n",
    "    Args:\n",
    "        agents_state : agent state. {0: Patient.susceptible, 1: Patient.colonized}  Size: (n_patients)\n",
    "        movement     : pd.Dataframe with patient locations and culture information.\n",
    "        parameters   : dictionary of parameters, contains importation rate (gamma), nosocomial transmission rate (beta),\n",
    "                        effective sensitivity (ro), and decolonization rate (alpha)\n",
    "    \"\"\"\n",
    "\n",
    "    n  = model_settings[\"n\"] # number of patients\n",
    "    m  = model_settings[\"m\"] # number of ensembles\n",
    "\n",
    "    p_update = agents_state.copy()\n",
    "    p_update = Patient.susceptible * (agents_state * np.random.random(size=(n, m)) <= alpha)\n",
    "\n",
    "    new_patients = movement[movement[\"first_day\"]==1][\"mrn_id\"].values\n",
    "\n",
    "    if new_patients.shape[0] > 0:\n",
    "        already_colonized         = p_update[new_patients, :]\n",
    "        # if a patient was colonized on a previous admission we keep the colonization status\n",
    "        p_update[new_patients, :] = Patient.colonized * (np.random.random(size=(new_patients.shape[0], m)) <= gamma) + already_colonized\n",
    "\n",
    "    p_update = np.clip(p_update, 0, 1) # clip those possible 'recolonized' upon readmission.\n",
    "\n",
    "    for i, ward_id in enumerate(movement[\"ward_id\"].unique()):\n",
    "        patients_ward = movement[movement[\"ward_id\"]==ward_id][\"mrn_id\"].values\n",
    "        λ_i = beta * np.sum(p_update[patients_ward, :]==Patient.colonized) / ward2size[ward_id]\n",
    "        p_update[patients_ward, :] = p_update[patients_ward, :] + Patient.colonized * (np.random.random(size=(patients_ward.shape[0], m)) <= λ_i)\n",
    "    p_update = np.clip(p_update, 0, 1)\n",
    "    return p_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movement_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m if_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNif\u001b[39m\u001b[38;5;124m\"\u001b[39m                : \u001b[38;5;241m30\u001b[39m,          \u001b[38;5;66;03m# number of iterations of the IF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_cooling\u001b[39m\u001b[38;5;124m\"\u001b[39m       : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# type of cooling schedule\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshrinkage_factor\u001b[39m\u001b[38;5;124m\"\u001b[39m   : \u001b[38;5;241m0.9\u001b[39m,         \u001b[38;5;66;03m# shrinkage factor for the cooling schedule\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minflation\u001b[39m\u001b[38;5;124m\"\u001b[39m          : \u001b[38;5;241m1.01\u001b[39m         \u001b[38;5;66;03m# inflation factor for spreading the variance after the EAKF step\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         }\n\u001b[1;32m     10\u001b[0m dates_simulation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m), end\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-02-28\u001b[39m\u001b[38;5;124m\"\u001b[39m), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m model_settings   \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m     13\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m---> 14\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[43mmovement_df\u001b[49m\u001b[38;5;241m.\u001b[39mmrn_id\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     15\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : movement_df\u001b[38;5;241m.\u001b[39mcluster\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     16\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdates\u001b[39m\u001b[38;5;124m\"\u001b[39m             : pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-02-28\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdates_simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m  : pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-02-28\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     18\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[38;5;28mlen\u001b[39m(dates_simulation),  \u001b[38;5;66;03m# time to run\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_build\u001b[39m\u001b[38;5;124m\"\u001b[39m         : \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28mlist\u001b[39m(wardid2buildingid\u001b[38;5;241m.\u001b[39mvalues()))),\n\u001b[1;32m     20\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28mlist\u001b[39m(wardid2buildingid\u001b[38;5;241m.\u001b[39mvalues())))\u001b[38;5;66;03m# observing at the building aggregation\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                 }\n\u001b[1;32m     23\u001b[0m assim_dates                       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020-02-01\u001b[39m\u001b[38;5;124m\"\u001b[39m), end\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-02-28\u001b[39m\u001b[38;5;124m\"\u001b[39m), freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW-Sun\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     24\u001b[0m assim_dates[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]                   \u001b[38;5;241m=\u001b[39m dates_simulation[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movement_df' is not defined"
     ]
    }
   ],
   "source": [
    "from models import observe_cluster_individual\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 300,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_obs_building_amro\n",
    "from infer_utils import run_amro_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IF-EAKF for amro:  E. coli\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 50\u001b[0m\n\u001b[1;32m     36\u001b[0m process       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t, x, θ: amr_abm_readmissions(t \u001b[38;5;241m=\u001b[39m t,\n\u001b[1;32m     37\u001b[0m                                                 agents_state   \u001b[38;5;241m=\u001b[39m x,\n\u001b[1;32m     38\u001b[0m                                                 gamma          \u001b[38;5;241m=\u001b[39m gamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                 ward2size      \u001b[38;5;241m=\u001b[39m ward2size,\n\u001b[1;32m     43\u001b[0m                                                 model_settings \u001b[38;5;241m=\u001b[39m model_settings)\n\u001b[1;32m     44\u001b[0m obs_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t, x, θ: observe_cluster_individual(t \u001b[38;5;241m=\u001b[39m t,\n\u001b[1;32m     45\u001b[0m                                                 agents_state   \u001b[38;5;241m=\u001b[39m x,\n\u001b[1;32m     46\u001b[0m                                                 rho            \u001b[38;5;241m=\u001b[39m θ[\u001b[38;5;241m0\u001b[39m, :],\n\u001b[1;32m     47\u001b[0m                                                 movement       \u001b[38;5;241m=\u001b[39m movement_df[movement_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mdates_simulation[t]],\n\u001b[1;32m     48\u001b[0m                                                 model_settings \u001b[38;5;241m=\u001b[39m model_settings)\n\u001b[0;32m---> 50\u001b[0m obs_df    \u001b[38;5;241m=\u001b[39m create_obs_building_amro(amro, \u001b[43mmodel_settings\u001b[49m, ward2buildingid, path_to_amro)\n\u001b[1;32m     51\u001b[0m run_amro_inference(f               \u001b[38;5;241m=\u001b[39m process,\n\u001b[1;32m     52\u001b[0m                     f0             \u001b[38;5;241m=\u001b[39m init_state,\n\u001b[1;32m     53\u001b[0m                     g              \u001b[38;5;241m=\u001b[39m obs_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     id_run         \u001b[38;5;241m=\u001b[39m id_run,\n\u001b[1;32m     58\u001b[0m                     path_to_save   \u001b[38;5;241m=\u001b[39m path_to_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_settings' is not defined"
     ]
    }
   ],
   "source": [
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_amro = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" )\n",
    "\n",
    "id_run                            = 0\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "    path_to_save = os.path.join(results2_dir, \"amro_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(os.path.join(results2_dir, \"amro_inferences\", \"abm\"), exist_ok=True)\n",
    "\n",
    "    gammas        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    if_settings[\"shrink_variance\"]    = False\n",
    "\n",
    "    for idx_gamma, gamma in enumerate(gammas):\n",
    "\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", \"individual_observation\",\n",
    "                                    f\"prevalence{idx_gamma}\", \"readmissions\")\n",
    "        os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "        if os.path.isfile(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\")):\n",
    "            continue\n",
    "\n",
    "        alpha         = 1/120\n",
    "        init_state    = lambda θ:       amr_abm_readmissions(t = 0,\n",
    "                                                        agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "        process       = lambda t, x, θ: amr_abm_readmissions(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "        obs_model = lambda t, x, θ: observe_cluster_individual(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        rho            = θ[0, :],\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        obs_df    = create_obs_building_amro(amro, model_settings, ward2buildingid, path_to_amro)\n",
    "        run_amro_inference(f               = process,\n",
    "                            f0             = init_state,\n",
    "                            g              = obs_model,\n",
    "                            obs_df         = obs_df,\n",
    "                            model_settings = model_settings,\n",
    "                            if_settings    = if_settings,\n",
    "                            id_run         = id_run,\n",
    "                            path_to_save   = path_to_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IF-EAKF for amro:  E. coli\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/results2/amro_inferences/abm/e_coli/infer_building/individual_observation/prevalence0/000posterior.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_gamma, gamma \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(gammas):\n\u001b[1;32m     20\u001b[0m     path_to_samples \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_to_save, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer_building\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividual_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevalence\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_gamma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     inference \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mid_run\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mposterior.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     θmle      \u001b[38;5;241m=\u001b[39m inference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     23\u001b[0m     θpost     \u001b[38;5;241m=\u001b[39m inference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/results2/amro_inferences/abm/e_coli/infer_building/individual_observation/prevalence0/000posterior.npz'"
     ]
    }
   ],
   "source": [
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_amro = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" )\n",
    "\n",
    "posterior_df = pd.DataFrame()\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "    path_to_save = os.path.join(results2_dir, \"amro_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(os.path.join(results2_dir, \"amro_inferences\", \"abm\"), exist_ok=True)\n",
    "\n",
    "    gammas        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    if_settings[\"shrink_variance\"]    = False\n",
    "\n",
    "    for idx_gamma, gamma in enumerate(gammas):\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", \"individual_observation\", f\"prevalence{idx_gamma}\")\n",
    "        inference = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "        θmle      = inference[\"mle\"]\n",
    "        θpost     = inference[\"posterior\"]\n",
    "        Nif       = θpost.shape[-1]\n",
    "\n",
    "        ρ_post = θpost[0, :, :, :].mean(-2).flatten()\n",
    "        β_post = θpost[1, :, :, :].mean(-2).flatten()\n",
    "\n",
    "        post_df             = pd.DataFrame(columns=[\"value\", \"param\", \"ens_id\", \"if_iter\"])\n",
    "        post_df[\"value\"]    = np.concatenate([ρ_post, β_post])\n",
    "        post_df[\"param\"]    = [\"ρ\"] * len(ρ_post) + [\"β\"] * len(β_post)\n",
    "        post_df[\"if_iter\"]  = flatten_list([list(range(Nif)) * model_settings[\"m\"] ] * 2 )\n",
    "        post_df[\"ens_id\"]   = flatten_list([[i] * Nif for i in range( model_settings[\"m\"])] * 2)\n",
    "        post_df[\"gamma\"]    = gamma\n",
    "        post_df[\"amro\"]     = amro\n",
    "        posterior_df        = pd.concat([posterior_df, post_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_fig = os.path.join(results2_dir, \"amro_inferences\", \"abm\", \"figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_amro = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" )\n",
    "posterior_df = pd.DataFrame()\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "    path_to_save = os.path.join(results2_dir, \"amro_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(os.path.join(results2_dir, \"amro_inferences\", \"abm\"), exist_ok=True)\n",
    "\n",
    "    gammas        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    if_settings[\"shrink_variance\"]    = False\n",
    "\n",
    "    for idx_gamma, gamma in enumerate(gammas):\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", \"individual_observation\", f\"prevalence{idx_gamma}\")\n",
    "        inference = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "        θmle      = inference[\"mle\"]\n",
    "        θpost     = inference[\"posterior\"]\n",
    "        Nif       = θpost.shape[-1]\n",
    "\n",
    "        ρ_post = θpost[0, :, :, :].mean(-2).flatten()\n",
    "        β_post = θpost[1, :, :, :].mean(-2).flatten()\n",
    "\n",
    "        post_df                = pd.DataFrame(columns=[\"value\", \"param\", \"ens_id\", \"if_iter\"])\n",
    "        post_df[\"value\"]       = np.concatenate([ρ_post, β_post])\n",
    "        post_df[\"param\"]    = [\"ρ\"] * len(ρ_post) + [\"β\"] * len(β_post)\n",
    "        post_df[\"if_iter\"]  = flatten_list([list(range(Nif)) * model_settings[\"m\"] ] * 2 )\n",
    "        post_df[\"ens_id\"]   = flatten_list([[i] * Nif for i in range( model_settings[\"m\"])] * 2)\n",
    "        post_df[\"gamma\"]    = gamma\n",
    "        post_df[\"amro\"]     = amro\n",
    "        posterior_df        = pd.concat([posterior_df, post_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_fig = os.path.join(results2_dir, \"amro_inferences\", \"abm\", \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils_local import plot_utils\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "COLORS_GAMMA = [\"#ff5e5b\", \"#00cecb\", \"mediumpurple\"]\n",
    "CMAPS_GAMMA  = [\"Reds\", \"Blues\", \"Purples\"]\n",
    "v_df = posterior_df[posterior_df[\"if_iter\"] == Nif-1]\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(16.5, 9.2), sharex=False, sharey=False)\n",
    "\n",
    "for idx_axi, axi in enumerate(ax.flatten()):\n",
    "    amro    = amro_search[idx_axi]\n",
    "    amro_df = v_df[v_df.amro==amro]\n",
    "    gammas  = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    for idx_g, gamma in enumerate(gammas):\n",
    "        rho_df  = amro_df.query(f\"gamma=={gamma} and param=='ρ'\")\n",
    "        beta_df = amro_df.query(f\"gamma=={gamma} and param=='β'\")\n",
    "\n",
    "        sns.kdeplot(ax    = axi,\n",
    "                    x     = rho_df[\"value\"].values * 100,\n",
    "                    y     = beta_df[\"value\"].values,\n",
    "                    cmap  = CMAPS_GAMMA[idx_g],\n",
    "                    fill  = True,\n",
    "                    alpha = 0.7)\n",
    "\n",
    "        axi.scatter(rho_df[\"value\"].values * 100,\n",
    "                    beta_df[\"value\"].values,\n",
    "                    facecolor = COLORS_GAMMA[idx_g],\n",
    "                    edgecolor = \"k\",\n",
    "                    alpha     = 0.5,\n",
    "                    s         = 10,\n",
    "                    label     = r\"$\\gamma$=\"+\"{:0.1f}%\".format(gamma*100))\n",
    "\n",
    "        axi.axhline(y     = np.mean(beta_df[\"value\"].values),\n",
    "                    ls    = \"--\",\n",
    "                    color = COLORS_GAMMA[idx_g])\n",
    "\n",
    "        axi.axvline(x     = np.mean(rho_df[\"value\"].values*100),\n",
    "                    ls    = \"--\",\n",
    "                    color = COLORS_GAMMA[idx_g])\n",
    "\n",
    "        axi.scatter(x          = np.mean(rho_df[\"value\"].values) * 100,\n",
    "                    y         = np.mean(beta_df[\"value\"].values),\n",
    "                    marker    = \"x\",\n",
    "                    facecolor = COLORS_GAMMA[idx_g],\n",
    "                    lw        = 3,\n",
    "                    s         = 100)\n",
    "\n",
    "    l = axi.legend(loc      = \"upper right\",\n",
    "                    frameon = False,\n",
    "                    prop    = {\"weight\": 'bold'})\n",
    "\n",
    "    for idx_t, text in enumerate(l.get_texts()):\n",
    "        text.set_color(COLORS_GAMMA[idx_t])\n",
    "\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "    axi.set_title(amro2title(amro))\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "\n",
    "ax[0, 0].set_ylabel(r\"$\\beta$\")\n",
    "ax[1, 0].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1, i].set_xlabel(r\"$\\rho$ (%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(path_to_save_fig, \"readmission_JointPosterior_gamma_sens.png\"), dpi=300, bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig     = plt.figure(constrained_layout=True, figsize=(16.2, 8.2))\n",
    "subfigs = fig.subfigures(2, 1, hspace=0.1, wspace=0.2, height_ratios=[0.5, 0.5])\n",
    "ax      = subfigs[0].subplots(2, 4, sharex=\"col\")\n",
    "\n",
    "for idx_ax in range(4):\n",
    "    amro                 = amro_search[idx_ax]\n",
    "    amro_df              = v_df[v_df.amro==amro]\n",
    "    amro_df[\"gamma_plt\"] = np.round(amro_df.gamma.values * 100, 2)\n",
    "\n",
    "    rho_df              = amro_df.query(f\"param=='ρ'\")\n",
    "    beta_df             = amro_df.query(f\"param=='β'\")\n",
    "\n",
    "    sns.boxplot(\n",
    "        ax         = ax[0, idx_ax],\n",
    "        data       = beta_df,\n",
    "        x          = \"gamma_plt\",\n",
    "        y          = \"value\",\n",
    "        hue        = \"gamma_plt\",\n",
    "        notch      = True,\n",
    "        dodge      = False,\n",
    "        width      = .3,\n",
    "        showcaps   = False,\n",
    "        palette    = COLORS_GAMMA,\n",
    "        showfliers = False)\n",
    "\n",
    "    rho_df[\"value\"] = rho_df[\"value\"].map(lambda x: x*100)\n",
    "    sns.boxplot(\n",
    "        ax         = ax[1, idx_ax],\n",
    "        data       = rho_df,\n",
    "        x          = \"gamma_plt\",\n",
    "        y          = \"value\",\n",
    "        hue        = \"gamma_plt\",\n",
    "        notch      = True,\n",
    "        dodge      = False,\n",
    "        width      = .3,\n",
    "        showcaps   = False,\n",
    "        palette    = COLORS_GAMMA,\n",
    "        showfliers = False)\n",
    "\n",
    "    ax[0, idx_ax].set_title(amro2title(amro))\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "    axi.legend().remove()\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "ax[1, 0].set_ylabel(r\"$\\rho$ (%)\")\n",
    "ax[0, 0].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1, i].set_xlabel(r\"$\\gamma$ (%)\")\n",
    "fig.subplots_adjust(left=0.1, bottom=0.5, right=0.95, top=0.6, wspace=0.9, hspace=0.9)\n",
    "\n",
    "####\n",
    "ax    = subfigs[1].subplots(2, 4, sharex=\"col\")\n",
    "\n",
    "for idx_ax in range(4, 8):\n",
    "    amro                 = amro_search[idx_ax]\n",
    "    amro_df              = v_df[v_df.amro==amro]\n",
    "    amro_df[\"gamma_plt\"] = np.round(amro_df.gamma.values * 100, 2)\n",
    "\n",
    "    rho_df          = amro_df.query(f\"param=='ρ'\")\n",
    "    beta_df         = amro_df.query(f\"param=='β'\")\n",
    "    rho_df[\"value\"] = rho_df[\"value\"].map(lambda x: x*100)\n",
    "\n",
    "    sns.boxplot(\n",
    "        ax         = ax[0, idx_ax - 4],\n",
    "        data       = rho_df,\n",
    "        x          = \"gamma_plt\",\n",
    "        y          = \"value\",\n",
    "        hue        = \"gamma_plt\",\n",
    "        notch      = True,\n",
    "        dodge      = False,\n",
    "        width      = .3,\n",
    "        showcaps   = False,\n",
    "        palette    = COLORS_GAMMA,\n",
    "        showfliers = False)\n",
    "\n",
    "    sns.boxplot(\n",
    "        ax         = ax[1, idx_ax- 4],\n",
    "        data       = beta_df,\n",
    "        x          = \"gamma_plt\",\n",
    "        y          = \"value\",\n",
    "        hue        = \"gamma_plt\",\n",
    "        notch      = True,\n",
    "        dodge      = False,\n",
    "        width      = .3,\n",
    "        showcaps   = False,\n",
    "        palette    = COLORS_GAMMA,\n",
    "        showfliers = False)\n",
    "\n",
    "    ax[0, idx_ax - 4].set_title(amro2title(amro))\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "    axi.legend().remove()\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "\n",
    "ax[1, 0].set_ylabel(r\"$\\rho$ (%)\")\n",
    "ax[0, 0].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1, i].set_xlabel(r\"$\\gamma$ (%)\")\n",
    "\n",
    "fig.subplots_adjust(left=0.1, bottom=0.5, right=0.95, top=0.6, wspace=0.9, hspace=0.3)\n",
    "\n",
    "fig.savefig(os.path.join(path_to_save_fig, \"BoxPlot_gamma_sens_betaVsrho.png\"), dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
