{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir           = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population_data(path_to_file, date_start=pd.to_datetime(\"2020-02-01\"), date_end=pd.to_datetime(\"2021-02-28\")):\n",
    "\n",
    "    dates_simulation = pd.date_range(start=date_start, end=date_end, freq=\"D\")\n",
    "\n",
    "    data_df  = pd.read_csv( path_to_file, parse_dates=['date'])\n",
    "    data_df  = data_df[data_df.date.isin(dates_simulation)]\n",
    "    A_df     = pd.pivot(data_df, index='ward', columns='date', values='num_admitted')\n",
    "    D_df     = pd.pivot(data_df, index='ward', columns='date', values='num_discharged')\n",
    "    H_df     = pd.pivot(data_df, index='ward', columns='date', values='num_hospitalized')\n",
    "    tests_df = pd.pivot(data_df, index='ward', columns='date', values='num_tested')\n",
    "    Hmean_df = H_df.mean(axis=1)\n",
    "\n",
    "    return A_df, D_df, H_df, tests_df, Hmean_df\n",
    "\n",
    "def create_time_transfers(path_to_file, num_wards, ward_names, date_start=pd.to_datetime(\"2020-02-01\"), date_end=pd.to_datetime(\"2021-02-28\")):\n",
    "\n",
    "    dates_simulation = pd.date_range(start=date_start, end=date_end, freq=\"D\")\n",
    "    transfers_df     = pd.read_csv(path_to_file, parse_dates=['date'])\n",
    "    transfers_df     = transfers_df[transfers_df.date.isin(dates_simulation)]\n",
    "    M_df             = np.zeros((num_wards, num_wards, len(dates_simulation)+1))\n",
    "\n",
    "    for i in range(num_wards):\n",
    "        ward_from = ward_names[i]\n",
    "        for j in range(num_wards):\n",
    "            ward_to      = ward_names[j]\n",
    "            transfers_ij = transfers_df[(transfers_df.ward_from==ward_from) & (transfers_df.ward_to==ward_to)]\n",
    "\n",
    "            if(transfers_ij.shape[0] > 0) :\n",
    "                dates_ij                = transfers_ij.date.values\n",
    "                dates_ind               = np.where(np.in1d(dates_ij, dates_simulation))[0]\n",
    "                transfered              = transfers_ij.num_transfered.values\n",
    "                M_df[i, j, dates_ind-1] = transfered\n",
    "\n",
    "    return M_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ward_counts = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"counts_ward.csv\" )\n",
    "path_to_ward_transf = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"transfers_ward.csv\" )\n",
    "\n",
    "\n",
    "A_df, D_df, H_df, tests_df, Hmean_df = create_population_data(path_to_ward_counts)\n",
    "\n",
    "num_wards  = len(Hmean_df)\n",
    "ward_names = list(Hmean_df.index)\n",
    "M_df       = create_time_transfers(path_to_ward_transf, num_wards=num_wards, ward_names=ward_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we want to choose synthetic scenarios that overall reproduce the synthetic observations, so we are going to use the stuff above (in the GridSearch) to sample from the parameter space and create the synthetic scenarios randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def return_score_cutoff(score, cut_off_prob=0.05):\n",
    "    freq, score = np.histogram(score, bins=100, density=True)\n",
    "    freq_cum    = np.cumsum(freq); freq_cum = freq_cum/freq_cum[-1]\n",
    "    score       = score[1:]\n",
    "    f_cum       = UnivariateSpline(score, freq_cum, s=0.001)\n",
    "    sc_range    = np.linspace(np.min(score), np.max(score), 1000)\n",
    "    score_cut   = sc_range[np.argmin(np.abs(f_cum(sc_range) * 100 - cut_off_prob*100))]\n",
    "    return score_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "wardid2buildingid            = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import process_metapop, observe_metapop, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "from misc import amro2cute\n",
    "\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "num_pop          = num_wards\n",
    "\n",
    "if_settings = {\n",
    "   \"Nif\"                : 20,          # number of iterations of the IF\n",
    "   \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "   \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "   \"inflation\"          : 1.01,        # inflation factor for spreading the variance after the EAKF step\n",
    "}\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],            # importation and transmission rate\n",
    "    \"p\"           : 2,                     # number of parameters\n",
    "    \"k\"           : num_pop,               # number of observations | We are just observing carriage\n",
    "    \"n\"           : 3*num_pop,             # number of state variables / dimension of the state space\n",
    "    \"dt\"          : 1,                     # time step\n",
    "    \"T\"           : len(dates_simulation), # time to run\n",
    "    \"m\"           : 300,                   # number of ensembles\n",
    "    \"stochastic\"  : True,                  # is stochastic\n",
    "    \"num_pop\"     : num_pop,\n",
    "    \"dates\"       : dates_simulation\n",
    "    }\n",
    "\n",
    "delta = 1/120  # decolonization rate\n",
    "\n",
    "A     = A_df.to_numpy()\n",
    "D     = D_df.to_numpy()\n",
    "H     = H_df.to_numpy()\n",
    "M     = M_df\n",
    "tests = tests_df.to_numpy()\n",
    "\n",
    "# Process model for the ifeakf | model(x, gamma, beta, delta, rho, sigma, pop, m=1, stochastic=True)\n",
    "process_model_gamma = lambda t, x, θ, gamma : process_metapop(t, x,\n",
    "                                            gamma = gamma * np.ones(model_settings[\"m\"]),\n",
    "                                            beta  = θ[1, :],\n",
    "                                            delta = delta,\n",
    "                                            Nmean = np.expand_dims(Hmean_df, -1),\n",
    "                                            N     = H[:, [t]],\n",
    "                                            A     = A[:, [t]],\n",
    "                                            D     = D[:, [t]],\n",
    "                                            M     = M[:, :, t])\n",
    "\n",
    "# f0 model for the ifeakf            | initial_condition(c0, pop=2000, m=300)\n",
    "initial_guess_x0_gamma  = lambda θ, gamma:  init_metapop(\n",
    "                                                N0             = H[:, 0],\n",
    "                                                c0             = gamma, # importation rate\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "# Observational model for the ifeakf |  g(t, x, rho)\n",
    "observational_model  = lambda t, x, θ: observe_metapop(t, x,\n",
    "                                                rho            = θ[0, :],\n",
    "                                                N              = H[:, [t]],\n",
    "                                                num_tests      = tests[:, [t]],\n",
    "                                                model_settings = model_settings,\n",
    "                                                ward2cluster   = wardid2buildingid)\n",
    "\n",
    "def observe_metapop_cluster(t, x, N, rho, num_tests, ward2cluster):\n",
    "    \"\"\" Observational model\n",
    "        Args:\n",
    "            t (int):      Time\n",
    "            x (np.array): State space\n",
    "            rho (float):  Observation probability\n",
    "        Returns:\n",
    "            y (np.array): Observed carriers ~ Binomial(C, rho).\n",
    "    \"\"\"\n",
    "\n",
    "    m         = model_settings[\"m\"]\n",
    "    num_pop   = model_settings[\"num_pop\"]\n",
    "    num_build = model_settings[\"num_build\"]\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.clip(np.nan_to_num(x[0, :, :]/N), 0, 1)\n",
    "\n",
    "    observed_colonized = np.random.binomial(list(num_tests * np.ones((num_pop, m))), rho * c)  # Shape [num_pop, m]\n",
    "    # need to resample this to [num_buildings x m] (maybe using the same buildings that rami used)\n",
    "    obs_col_building = np.zeros((num_build, m))\n",
    "\n",
    "    for i in range(num_build):\n",
    "        obs_col_building[ward2cluster[i], :] += observed_colonized[i, :]\n",
    "\n",
    "    return obs_col_building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "from ifeakf import ifeakf\n",
    "\n",
    "\n",
    "def run_amro_synthetic(amro, id_run=0):\n",
    "\n",
    "    cut_off_prob = 5/100\n",
    "    amro_prev_df = pd.read_csv(os.path.join(\"..\", \"data\", \"amro_prevalence.csv\"))\n",
    "    dates_infer  = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "    gs_df        = pd.read_csv( os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\") ).drop(columns=[\"Unnamed: 0\"])\n",
    "    gamma        = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "\n",
    "    sc_cutoff    = return_score_cutoff(gs_df.crps, cut_off_prob=cut_off_prob)\n",
    "    gs_df        = gs_df[gs_df.crps <= sc_cutoff].reset_index(drop=True)\n",
    "    scenarios_df = gs_df.copy()\n",
    "    scenarios_df = scenarios_df.sample(n=10); scenarios_df = scenarios_df[[\"rho\", \"beta\", \"crps\", \"calibration_score\"]].reset_index(drop=True)\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"no_state_space\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "    scenarios_df.to_csv(os.path.join(path_to_save, f\"scenarios{id_run}.csv\"))\n",
    "\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "\n",
    "        model_settings[\"param_truth\"] = [row[\"rho\"], row[\"beta\"]]\n",
    "        model_settings[\"num_build\"] = len(np.unique(list(wardid2buildingid.values())))\n",
    "        model_settings[\"k\"]         = model_settings[\"num_build\"] # observing at that aggregation\n",
    "\n",
    "        process_model        = lambda t, x, θ: process_model_gamma(t, x, θ, gamma=gamma)\n",
    "        init_conditions      = lambda θ: initial_guess_x0_gamma(θ, gamma=gamma)\n",
    "        observational_model  = lambda t, x, θ: observe_metapop_cluster(t, x,\n",
    "                                                    N            = H[:, [t]],\n",
    "                                                    rho          = θ[0, :],\n",
    "                                                    num_tests    = tests[:, [t]],\n",
    "                                                    ward2cluster = wardid2buildingid)\n",
    "\n",
    "        θtruth       = np.array([model_settings[\"param_truth\"]]).T * np.ones((model_settings[\"p\"], model_settings[\"m\"]))\n",
    "        x_sim, y_sim = simulate_metapop(\n",
    "                        process_model       = process_model,\n",
    "                        observational_model = observational_model,\n",
    "                        init_state          = init_conditions,\n",
    "                        θsim                = θtruth,\n",
    "                        model_settings      = model_settings)\n",
    "\n",
    "        idx_infer      = np.random.randint(y_sim.shape[1])\n",
    "        obs_infer      = y_sim[:, :, idx_infer].transpose(1, 0)\n",
    "\n",
    "        obs_df = pd.DataFrame(index=dates_infer)\n",
    "        for i in range(model_settings[\"num_build\"]) :\n",
    "            obs_df['y'+str(i+1)]   = obs_infer[i, :]\n",
    "            obs_df['oev'+str(i+1)] = 1 +(0.2 * obs_df['y'+str(i+1)].values)**2\n",
    "        obs_df                  = obs_df.resample(\"W-Sun\").sum()\n",
    "        obs_df.index.values[-1] = model_settings[\"dates\"][-1]\n",
    "\n",
    "\n",
    "        ρmin           = 0.01 # test sensitivity minimum\n",
    "        ρmax           = 0.2  # test sensitivity maximum\n",
    "        βmin           = 0.00 # transmission rate minimum\n",
    "        βmax           = 0.5  # transmission rate maximum\n",
    "\n",
    "        max_total_pop     = np.max(H.sum(axis=0))\n",
    "        state_space_range = np.array([0, max_total_pop])\n",
    "        parameters_range  = np.array([[ρmin, ρmax], [βmin, βmax]])\n",
    "        σ_perturb         = np.array([(ρmax-ρmin)/4, (βmax-βmin)/4])\n",
    "\n",
    "        if_settings[\"assimilation_dates\"] = obs_df.index.values\n",
    "        if_settings[\"adjust_state_space\"] = False  # for comparing with the abm\n",
    "\n",
    "        path_to_save_sce = os.path.join(results2_dir, \"synthetic_inferences\", \"no_state_space\", f\"{amro2cute(amro)}\", f\"scenario{idx_row+1}\")\n",
    "        os.makedirs(path_to_save_sce, exist_ok=True)\n",
    "\n",
    "        θmle, θpost = ifeakf(process_model                = process_model,\n",
    "                                observational_model       = observational_model,\n",
    "                                state_space_initial_guess = init_conditions,\n",
    "                                observations_df           = obs_df,\n",
    "                                parameters_range          = parameters_range,\n",
    "                                state_space_range         = state_space_range,\n",
    "                                model_settings            = model_settings,\n",
    "                                if_settings               = if_settings,\n",
    "                                perturbation              = σ_perturb)\n",
    "\n",
    "        np.savez_compressed(os.path.join(path_to_save_sce, f\"{str(id_run).zfill(3)}posterior.npz\"),\n",
    "                                        mle           = θmle,\n",
    "                                        posterior     = θpost,\n",
    "                                        state_space   = x_sim,\n",
    "                                        observations  = y_sim,\n",
    "                                        teta_truth    = θtruth,\n",
    "                                        idx_infer     = idx_infer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/results2/synthetic_inferences/no_state_space/e_coli/scenario1/000posterior.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m amro_search  \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mESCHERICHIA COLI\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKLEBSIELLA PNEUMONIAE\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m'\u001b[39m\u001b[39mPSEUDOMONAS AERUGINOSA\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mMETHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mSTAPHYLOCOCCUS EPIDERMIDIS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mENTEROCOCCUS FAECALIS\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mENTEROCOCCUS FAECIUM\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m amro \u001b[39min\u001b[39;00m amro_search:\n\u001b[0;32m----> 6\u001b[0m     run_amro_synthetic(amro)\n",
      "Cell \u001b[0;32mIn [7], line 82\u001b[0m, in \u001b[0;36mrun_amro_synthetic\u001b[0;34m(amro, id_run)\u001b[0m\n\u001b[1;32m     70\u001b[0m os\u001b[39m.\u001b[39mmakedirs(path_to_save, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m θmle, θpost \u001b[39m=\u001b[39m ifeakf(process_model                \u001b[39m=\u001b[39m process_model,\n\u001b[1;32m     73\u001b[0m                         observational_model       \u001b[39m=\u001b[39m observational_model,\n\u001b[1;32m     74\u001b[0m                         state_space_initial_guess \u001b[39m=\u001b[39m init_conditions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m                         if_settings               \u001b[39m=\u001b[39m if_settings,\n\u001b[1;32m     80\u001b[0m                         perturbation              \u001b[39m=\u001b[39m σ_perturb)\n\u001b[0;32m---> 82\u001b[0m np\u001b[39m.\u001b[39;49msavez_compressed(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path_to_save_sce, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mstr\u001b[39;49m(id_run)\u001b[39m.\u001b[39;49mzfill(\u001b[39m3\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39mposterior.npz\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     83\u001b[0m                                 mle           \u001b[39m=\u001b[39;49m θmle,\n\u001b[1;32m     84\u001b[0m                                 posterior     \u001b[39m=\u001b[39;49m θpost,\n\u001b[1;32m     85\u001b[0m                                 state_space   \u001b[39m=\u001b[39;49m x_sim,\n\u001b[1;32m     86\u001b[0m                                 observations  \u001b[39m=\u001b[39;49m y_sim,\n\u001b[1;32m     87\u001b[0m                                 teta_truth    \u001b[39m=\u001b[39;49m θtruth,\n\u001b[1;32m     88\u001b[0m                                 idx_infer     \u001b[39m=\u001b[39;49m idx_infer)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pompjax/lib/python3.8/site-packages/numpy/lib/npyio.py:666\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[1;32m    604\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavez_compressed\u001b[39m(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    605\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[39m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \n\u001b[1;32m    665\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     _savez(file, args, kwds, \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pompjax/lib/python3.8/site-packages/numpy/lib/npyio.py:692\u001b[0m, in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m     compression \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39mZIP_STORED\n\u001b[0;32m--> 692\u001b[0m zipf \u001b[39m=\u001b[39m zipfile_factory(file, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, compression\u001b[39m=\u001b[39;49mcompression)\n\u001b[1;32m    694\u001b[0m \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m namedict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    695\u001b[0m     fname \u001b[39m=\u001b[39m key \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pompjax/lib/python3.8/site-packages/numpy/lib/npyio.py:103\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\n\u001b[1;32m    102\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mallowZip64\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m zipfile\u001b[39m.\u001b[39;49mZipFile(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pompjax/lib/python3.8/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[1;32m   1252\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/results2/synthetic_inferences/no_state_space/e_coli/scenario1/000posterior.npz'"
     ]
    }
   ],
   "source": [
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "for amro in amro_search:\n",
    "    run_amro_synthetic(amro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pompjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
