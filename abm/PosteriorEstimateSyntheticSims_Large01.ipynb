{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from abm_utils import empirical_prevalence, simulate_abm, create_obs_infer\n",
    "from utils_local.misc import amro2title, amro2cute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/701878645.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia', \"Rest\"]\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_37865/1486530046.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "gammas_search = [0.25, 0.5]\n",
    "betas_search  = [0.01, 0.05, 0.1]\n",
    "rho_search    = [1/100, 5/100, 10/100, 18/100]\n",
    "\n",
    "idx_sce = 0\n",
    "scenarios_large_df = pd.DataFrame(columns=[\"scenario\", \"gamma\", \"beta\", \"rho\"])\n",
    "for g in gammas_search:\n",
    "    for b in betas_search:\n",
    "        for r in rho_search:\n",
    "            scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
    "            idx_sce += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import amr_abm, observe_cluster_individual\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 200,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "id_run                            = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 270.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx_row, row in tqdm.tqdm(scenarios_large_df.iterrows(), total=len(scenarios_large_df)):\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"])\n",
    "    gamma        = row[\"gamma\"]\n",
    "\n",
    "    path_to_samples = os.path.join(path_to_save, \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "    inference       = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "    if os.path.isfile(os.path.join(path_to_samples,  f\"{str(id_run).zfill(3)}sim_post.npz\")):\n",
    "        continue\n",
    "\n",
    "    alpha = 1/120\n",
    "    f0    = lambda θ:       amr_abm(t = 0,\n",
    "                                                    agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                                    gamma          = gamma,\n",
    "                                                    beta           = θ[1, :],\n",
    "                                                    alpha          = alpha,\n",
    "                                                    movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                                    ward2size      = ward2size,\n",
    "                                                    model_settings = model_settings)\n",
    "    f       = lambda t, x, θ: amr_abm(t = t,\n",
    "                                                    agents_state   = x,\n",
    "                                                    gamma          = gamma,\n",
    "                                                    beta           = θ[1, :],\n",
    "                                                    alpha          = alpha,\n",
    "                                                    movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                    ward2size      = ward2size,\n",
    "                                                    model_settings = model_settings)\n",
    "    g = lambda t, x, θ: observe_cluster_individual(t = t,\n",
    "                                                    agents_state   = x,\n",
    "                                                    rho            = θ[0, :],\n",
    "                                                    movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                    model_settings = model_settings)\n",
    "\n",
    "\n",
    "    θ       = inference[\"posterior\"].mean(-2)[:, :, -1]\n",
    "    y_dist  = inference[\"observations\"]\n",
    "    i_infer = inference[\"idx_infer\"]\n",
    "    y_infer = y_dist[:, :, i_infer]\n",
    "\n",
    "    ysim = simulate_abm(f, f0, g, θ, model_settings)\n",
    "    np.savez_compressed(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}sim_post.npz\"),\n",
    "                                    y           = ysim,\n",
    "                                    y_data      = y_infer,\n",
    "                                    y_dist      = y_dist,\n",
    "                                    posterior   = θ,\n",
    "                                    param_truth = np.array([row[\"rho\"], row[\"beta\"]]),\n",
    "                                    gamma       = gamma,\n",
    "                                    idx_infer   = i_infer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.calibration import calibration\n",
    "def create_sim_df(sim_samples, model_settings):\n",
    "    \"\"\" Sample from the posterior simultion\n",
    "\n",
    "    Args:\n",
    "        sim_samples: Array with shape (k: num_observations, m: num_samples, T: length of simulation)\n",
    "        model_settings: _description_\n",
    "    \"\"\"\n",
    "    k, m , T = sim_samples.shape\n",
    "    y = sim_samples\n",
    "\n",
    "    sim_df = pd.DataFrame()\n",
    "    for ki in range(model_settings[\"k\"]):\n",
    "        df           = pd.DataFrame(np.squeeze(y[ki, :, :]).flatten(), columns=[\"value\"])\n",
    "        df[\"date\"]   = flatten_list([list(model_settings[\"dates_simulation\"])] * model_settings[\"m\"])\n",
    "        df[\"ens_id\"] = flatten_list([[mi]*model_settings[\"T\"] for mi in range(model_settings[\"m\"])])\n",
    "        df           = df.set_index([\"date\", \"ens_id\"]).unstack([1]).resample(\"W-Sun\").sum().stack().reset_index()\n",
    "        df[\"yi\"]     = ki\n",
    "        sim_df       = pd.concat([sim_df, df])\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_fig = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdates\n",
    "from utils import create_df_response\n",
    "from utils_local import plot_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_row, row = next(scenarios_large_df.iterrows())\n",
    "\n",
    "for idx_gamma, gamma in enumerate(gammas_search):\n",
    "\n",
    "    if os.path.isfile(os.path.join(path_to_save_fig, \"sim_posterior{}.png\".format(gamma))):\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12.5, 7.2), sharex=True, sharey=False)\n",
    "    for id_ax, ax in enumerate(axes.flatten()):\n",
    "        sce_g_df = scenarios_large_df[scenarios_large_df[\"gamma\"]==gamma]\n",
    "        scenario = sce_g_df.iloc[id_ax][\"scenario\"]\n",
    "\n",
    "        path_to_save    = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", scenario)\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", scenario)\n",
    "\n",
    "        post_sim     = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}sim_post.npz\"))\n",
    "\n",
    "        obs_infer_df         = pd.DataFrame(post_sim[\"y_data\"], columns=[f\"y{i+1}\" for i in range(model_settings[\"k\"])])# at hospital level\n",
    "        obs_infer_df[\"date\"] = model_settings[\"dates_simulation\"]\n",
    "        obs_infer_df         = obs_infer_df.set_index(\"date\").resample(\"W-Sun\").sum()\n",
    "        obs_infer_df         = pd.DataFrame(obs_infer_df.sum(1)).rename(columns={0: \"value\"})\n",
    "\n",
    "        obs_all_df  = create_sim_df(post_sim[\"y_dist\"].transpose(1, 2, 0), model_settings).groupby([\"date\", \"ens_id\"]).sum()[[\"value\"]].unstack([1]).resample(\"W-Sun\").sum().stack().reset_index()\n",
    "        sim_df      = create_sim_df(post_sim[\"y\"].transpose(1, 2, 0), model_settings).groupby([\"date\", \"ens_id\"]).sum()[[\"value\"]].unstack([1]).resample(\"W-Sun\").sum().stack().reset_index()\n",
    "\n",
    "        hosp_samples   = sim_df.pivot(index=\"date\", columns=\"ens_id\", values=\"value\").to_numpy()\n",
    "        obs_truth_dist = obs_all_df.pivot(index=\"date\", columns=\"ens_id\", values=\"value\").to_numpy()\n",
    "\n",
    "        hosp_sim_df   = create_df_response(np.squeeze(hosp_samples),   time = len(if_settings[\"assimilation_dates\"]), dates = if_settings[\"assimilation_dates\"])\n",
    "        hosp_truth_df = create_df_response(np.squeeze(obs_truth_dist), time = len(if_settings[\"assimilation_dates\"]), dates = if_settings[\"assimilation_dates\"])\n",
    "\n",
    "        ax.scatter(if_settings[\"assimilation_dates\"], obs_infer_df[\"value\"], color=\"k\", marker=\"o\", s=8, label=\"Obs. infer\")\n",
    "\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_sim_df[\"low_95\"], color=\"dodgerblue\", alpha=0.5, ls=\"--\", lw=1)\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_sim_df[\"high_95\"], color=\"dodgerblue\", alpha=0.5, ls=\"--\", lw=1)\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_sim_df[\"mean\"], color=\"dodgerblue\", label=\"Simulation\")\n",
    "\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_truth_df[\"low_95\"], color=\"crimson\", alpha=0.5, ls=\"-.\", lw=1)\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_truth_df[\"high_95\"], color=\"crimson\", alpha=0.5, ls=\"-.\", lw=1)\n",
    "        ax.plot(if_settings[\"assimilation_dates\"], hosp_truth_df[\"mean\"], color=\"crimson\", label=\"Truth\")\n",
    "\n",
    "        # set the y-spine\n",
    "        ax.spines['bottom'].set_position('zero')\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "    axes[0, 0].legend(loc=\"upper left\", fontsize=12)\n",
    "    axes[0, 0].set_ylim(axes[0, 1].get_ylim())\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[0, i].text(x     = 18296,\n",
    "                        y     = axes[0, i].get_ylim()[1],\n",
    "                        s     = r\"$\\rho$={}%\".format(rho_search[i] * 100),\n",
    "                        color = \"mediumpurple\")\n",
    "\n",
    "    for i in range(3):\n",
    "        axes[i, 0].text(x        = 18126,\n",
    "                        y        = 2,\n",
    "                        s        = r\"$\\beta$={}\".format(betas_search[i]),\n",
    "                        color    = \"mediumpurple\",\n",
    "                        rotation = 90)\n",
    "    fig.suptitle(\"Synthetic inferences, $\\gamma$={:0.0f}%\".format(gamma*100), x=0.3, fontsize=19)\n",
    "    fig.savefig(os.path.join(path_to_save_fig, \"sim_posterior{}.png\".format(gamma)), dpi=300, bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = gammas_search[0]\n",
    "id_ax = 0\n",
    "\n",
    "sce_g_df = scenarios_large_df[scenarios_large_df[\"gamma\"]==gamma]\n",
    "scenario = sce_g_df.iloc[id_ax][\"scenario\"]\n",
    "\n",
    "path_to_save    = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", scenario)\n",
    "path_to_samples = os.path.join(path_to_save, \"infer_building\", scenario)\n",
    "post_sim        = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}sim_post.npz\"))\n",
    "\n",
    "list(post_sim.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdates\n",
    "from utils import create_df_response\n",
    "from utils_local import plot_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_row, row = next(scenarios_large_df.iterrows())\n",
    "\n",
    "obs_infer_df = pd.DataFrame()\n",
    "obs_truth_df = pd.DataFrame()\n",
    "obs_sim_df   = pd.DataFrame()\n",
    "\n",
    "for idx_gamma, gamma in enumerate(gammas_search):\n",
    "    for id_ax, ax in enumerate(axes.flatten()):\n",
    "        sce_g_df = scenarios_large_df[scenarios_large_df[\"gamma\"]==gamma]\n",
    "        scenario = sce_g_df.iloc[id_ax][\"scenario\"]\n",
    "\n",
    "        path_to_save    = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", scenario)\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", scenario)\n",
    "        post_sim        = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}sim_post.npz\"))\n",
    "\n",
    "        for k in range(model_settings[\"k\"]):\n",
    "            if k ==5:\n",
    "                building = \"Rest\"\n",
    "            else:\n",
    "                building = selected_buildings[k]\n",
    "\n",
    "\n",
    "\n",
    "            y_infer = post_sim[\"y_data\"][:, k]\n",
    "            y_truth = create_df_response(post_sim[\"y_dist\"][:, k, :], time=len(model_settings[\"dates_simulation\"]))\n",
    "            y_sim   = create_df_response(post_sim[\"y\"][:, k, :],      time=len(model_settings[\"dates_simulation\"]))\n",
    "\n",
    "            y_truth[\"building\"] = building\n",
    "            y_sim[\"building\"]   = building\n",
    "\n",
    "            y_truth[\"gamma\"]    = gamma\n",
    "            y_truth[\"beta\"]     = post_sim[\"param_truth\"][1]\n",
    "            y_truth[\"rho\"]      = post_sim[\"param_truth\"][0]\n",
    "\n",
    "            y_sim[\"gamma\"]      = gamma\n",
    "            y_sim[\"beta\"]       = post_sim[\"param_truth\"][1]\n",
    "            y_sim[\"rho\"]        = post_sim[\"param_truth\"][0]\n",
    "\n",
    "            y_sim[\"scenario\"]   = scenario\n",
    "            y_truth[\"scenario\"] = scenario\n",
    "\n",
    "            obs_infer_df  = pd.concat([obs_infer_df,\n",
    "                                    pd.DataFrame({\"date\": model_settings[\"dates_simulation\"],\n",
    "                                                \"value\": y_infer,\n",
    "                                                \"building\": building,\n",
    "                                                \"gamma\": gamma, \"beta\": row.beta, \"rho\": row.rho,\n",
    "                                                \"scenario\": scenario})])\n",
    "            obs_truth_df = pd.concat([obs_truth_df, y_truth])\n",
    "            obs_sim_df   = pd.concat([obs_sim_df, y_sim])\n",
    "\n",
    "obs_infer_df.to_csv(os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"obs_infer.csv\"))\n",
    "obs_truth_df.to_csv(os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"obs_truth.csv\"))\n",
    "obs_sim_df.to_csv(os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"obs_sim.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chaosdonkey06/Dropbox/shaman-lab/amr-hospitals/results2/synthetic_inferences/abm/large_search'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
