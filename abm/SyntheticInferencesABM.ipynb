{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from utils_local.misc import amro2title, amro2cute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\"):\n",
    "    amro_prev_df = pd.read_csv(path_to_prev)\n",
    "    gamma        = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "    return gamma\n",
    "\n",
    "def simulate_abm(f, f0, g, θ, model_settings):\n",
    "    dates_simulation = model_settings[\"dates_simulation\"]\n",
    "\n",
    "    x = f0(θ)\n",
    "\n",
    "    observations          = np.full((len(dates_simulation), model_settings[\"k\"], model_settings[\"m\"]), np.nan)\n",
    "    observations[0, :, :] = g(0, x, θ)\n",
    "\n",
    "    for t, date in enumerate(dates_simulation[1:]):\n",
    "        x                       = f(t, x, θ)\n",
    "        observations[t+1, :, :] = g(t, x, θ)\n",
    "    return observations\n",
    "\n",
    "def create_obs_infer(obs_sim, idx_infer, dates, model_settings, resample=\"W-Sun\"):\n",
    "    # obs_sim \\in R^{[k x T x m]} as required by pompjax\n",
    "    infer_df = pd.DataFrame(index=dates)\n",
    "    for i in range(model_settings[\"k\"]) :\n",
    "        infer_df['y'+str(i+1)]   = obs_sim[i, :, idx_infer]\n",
    "        infer_df['oev'+str(i+1)] = 1 +(0.2 * infer_df['y'+str(i+1)].values)**2\n",
    "    infer_df                     = infer_df.resample(resample).sum()\n",
    "    infer_df.index.values[-1]    = model_settings[\"dates\"][-1]\n",
    "    return infer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_66598/1610801969.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "from ifeakf import ifeakf\n",
    "\n",
    "def run_amro_synthetic(f, f0, g, fsim, model_settings, if_settings, id_run=0, path_to_save=None):\n",
    "    dates        = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "\n",
    "    θtruth  = np.array([model_settings[\"param_truth\"]]).T * np.ones((model_settings[\"p\"], model_settings[\"m\"]))\n",
    "\n",
    "\n",
    "    y_sim   = fsim(f               = f,\n",
    "                    g              = g,\n",
    "                    f0             = f0,\n",
    "                    θ              = θtruth,\n",
    "                    model_settings = model_settings)\n",
    "\n",
    "    idx_infer = np.random.randint(model_settings[\"m\"])\n",
    "    obs_df    = create_obs_infer(y_sim.transpose(1, 0, 2), idx_infer, dates, model_settings, resample=\"W-Sun\")\n",
    "\n",
    "    ρmin              = 0.01/2 # test sensitivity minimum\n",
    "    ρmax              = 0.2    # test sensitivity maximum\n",
    "    βmin              = 0.00   # transmission rate minimum\n",
    "    βmax              = 0.11   # transmission rate maximum\n",
    "\n",
    "    state_space_range = np.array([0, 1])\n",
    "    parameters_range  = np.array([[ρmin, ρmax],    [βmin, βmax]])\n",
    "    σ_perturb         = np.array([(ρmax - ρmin)/4, (βmax - βmin)/4]) # (i hve the gut feeling that 0.25 is too large)\n",
    "\n",
    "    θmle, θpost = ifeakf(process_model                = f,\n",
    "                            state_space_initial_guess = f0,\n",
    "                            observational_model       = g,\n",
    "                            observations_df           = obs_df,\n",
    "                            parameters_range          = parameters_range,\n",
    "                            state_space_range         = state_space_range,\n",
    "                            model_settings            = model_settings,\n",
    "                            if_settings               = if_settings,\n",
    "                            perturbation              = σ_perturb)\n",
    "\n",
    "    np.savez_compressed(os.path.join(path_to_save, f\"{str(id_run).zfill(3)}posterior.npz\"),\n",
    "                                    mle           = θmle,\n",
    "                                    posterior     = θpost,\n",
    "                                    observations  = y_sim,\n",
    "                                    teta_truth    = θtruth,\n",
    "                                    idx_infer     = idx_infer)\n",
    "\n",
    "    ρ_df = create_df_response(θpost[0, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "    β_df = create_df_response(θpost[1, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "\n",
    "    p_dfs             = [ρ_df, β_df]\n",
    "    param_label       = [\"ρ\", \"β\"]\n",
    "    parameters_range  = np.array([[ρmin, ρmax], [βmin, βmax]])\n",
    "\n",
    "    convergence_plot(θmle, p_dfs, parameters_range, param_label, param_truth=list(θtruth[:, 0]),\n",
    "                        path_to_save=os.path.join(path_to_save, f\"{str(id_run).zfill(3)}convergence.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def return_score_cutoff(score, cut_off_prob=0.05):\n",
    "    freq, score = np.histogram(score, bins=100, density=True)\n",
    "    freq_cum    = np.cumsum(freq); freq_cum = freq_cum/freq_cum[-1]\n",
    "    score       = score[1:]\n",
    "    f_cum       = UnivariateSpline(score, freq_cum, s=0.001)\n",
    "    sc_range    = np.linspace(np.min(score), np.max(score), 1000)\n",
    "    score_cut   = sc_range[np.argmin(np.abs(f_cum(sc_range) * 100 - cut_off_prob*100))]\n",
    "    return score_cut\n",
    "\n",
    "def sample_scenarios(path_to_grid_search, cut_off=10/100):\n",
    "    gs_df        = pd.read_csv( path_to_grid_search )\n",
    "    sc_cutoff    = return_score_cutoff(gs_df.crps, cut_off_prob=cut_off)\n",
    "    gs_df        = gs_df[gs_df.crps <= sc_cutoff].reset_index(drop=True)\n",
    "    scenarios_df = gs_df.copy()\n",
    "    scenarios_df = scenarios_df.sample(n=10); scenarios_df = scenarios_df[[\"rho\", \"beta\", \"crps\", \"calibration_score\"]].reset_index(drop=True)\n",
    "    return scenarios_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_scenarios         = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\")\n",
    "for amro in amro_search:\n",
    "    path_to_grid_search           = os.path.join(\"..\", \"preliminary_results\",  f\"crps_{amro2cute(amro)}.csv\")\n",
    "\n",
    "    os.makedirs(os.path.join(path_to_scenarios, f\"{amro2cute(amro)}\"), exist_ok=True)\n",
    "\n",
    "    if os.path.isfile(os.path.join(path_to_scenarios, f\"{amro2cute(amro)}\", \"scenarios.csv\")):\n",
    "        continue\n",
    "    else:\n",
    "        scenarios_df                  = sample_scenarios(path_to_grid_search, cut_off=10/100)\n",
    "        scenarios_df.to_csv(os.path.join(path_to_scenarios, f\"{amro2cute(amro)}\", \"scenarios.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import amr_abm, observe_cluster\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 20,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 200,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "id_run                            = 0\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(os.path.join(results2_dir, \"synthetic_inferences\", \"abm\"), exist_ok=True)\n",
    "\n",
    "    scenarios_df = pd.read_csv(os.path.join(path_to_save, \"scenarios.csv\"))\n",
    "    scenarios_df = scenarios_df.sample(n=5) # just use 5 scenarios\n",
    "    gamma        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "        print(f\"\\t Synthetic {idx_row+1}/{len(scenarios_df)}\", end=\"\\r\")\n",
    "\n",
    "        model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "        if_settings[\"adjust_state_space\"] = False\n",
    "\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "        os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "        if os.path.isfile(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\")):\n",
    "            continue\n",
    "\n",
    "        alpha               = 1/120\n",
    "        init_state          = lambda θ:       amr_abm(t = 0,\n",
    "                                                        agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        process       = lambda t, x, θ: amr_abm(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        obs_model = lambda t, x, θ: observe_cluster(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        rho            = θ[0, :],\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        run_amro_synthetic(f               = process,\n",
    "                            f0             = init_state,\n",
    "                            g              = obs_model,\n",
    "                            fsim           = simulate_abm,\n",
    "                            model_settings = model_settings,\n",
    "                            if_settings    = if_settings,\n",
    "                            id_run         = id_run,\n",
    "                            path_to_save   = path_to_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pannel of convergence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scenario3',\n",
       " 'scenario4',\n",
       " 'scenario5',\n",
       " 'scenario2',\n",
       " 'scenario10',\n",
       " 'scenario7',\n",
       " 'scenario9',\n",
       " 'scenario8',\n",
       " 'scenario1',\n",
       " 'scenario6']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amro = amro_search[0]\n",
    "path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "scenarios_df = pd.read_csv(os.path.join(path_to_save, \"scenarios.csv\"))\n",
    "\n",
    "os.listdir(os.path.join(path_to_save, \"infer_building\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IF-EAKF for amro:  E. coli\n",
      "Running IF-EAKF for amro:  K. pneumoniae\n"
     ]
    }
   ],
   "source": [
    "from utils_local.misc import amro2title, amro2cute\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "\n",
    "for idx_amro, amro in enumerate(amro_search):\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "    scenarios_df = pd.read_csv(os.path.join(path_to_save, \"scenarios.csv\"))\n",
    "\n",
    "    fig, axes = plt.subplots(len(scenarios_df), 2, figsize=(10, 12), sharex=True, sharey=\"col\")\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "\n",
    "        inference = np.load(os.path.join(path_to_save, \"infer_building\",\n",
    "                                        f\"scenario{idx_row+1}\", f\"{str(0).zfill(3)}posterior.npz\"))\n",
    "        θmle      = inference[\"mle\"]\n",
    "        θpost     = inference[\"posterior\"]\n",
    "        y_sim     = inference[\"observations\"]\n",
    "        θtruth    = inference[\"teta_truth\"]\n",
    "        idx_infer = inference[\"idx_infer\"]\n",
    "        Nif       = θpost.shape[-1]\n",
    "\n",
    "        ρ_df = create_df_response(θpost[0, :, :, :].mean(-2).T, time=Nif)\n",
    "        β_df = create_df_response(θpost[1, :, :, :].mean(-2).T, time=Nif)\n",
    "\n",
    "        p_dfs             = [ρ_df, β_df]\n",
    "        param_label       = [\"ρ\", \"β\"]\n",
    "\n",
    "        parameters_range  = np.array([[0.01/2, 20/100], [0, 0.11]])\n",
    "        convergence_plot(θmle, p_dfs, parameters_range, param_label, ax=axes[idx_row, :], fig=fig, param_truth=list(θtruth[:, 0]))\n",
    "        axes[idx_row, 0].legend().remove(); axes[idx_row, 1].legend().remove()\n",
    "        axes[idx_row, 1].set_xlabel(None)\n",
    "\n",
    "        axes[idx_row, 0].spines['right'].set_visible(False)\n",
    "        axes[idx_row, 0].spines['top'].set_visible(False)\n",
    "\n",
    "        axes[idx_row, 1].spines['right'].set_visible(False)\n",
    "        axes[idx_row, 1].spines['top'].set_visible(False)\n",
    "        axes[idx_row, 0].text(x=0.1, y=0.02, s=f\"Scenario {idx_row+1}\", weight='bold')\n",
    "\n",
    "    axes[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0.0, 1.65), ncol=4)\n",
    "    axes[idx_row, 0].set_xlabel(\"Iteration\")\n",
    "    axes[idx_row, 1].set_xlabel(\"Iteration\")\n",
    "\n",
    "    fig.suptitle(f\"Process model at ward level ($n=220$), inference at building level ($k=6$)\\n for {amro2title(amro)}, not adjusting the state space\", x=0.5)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(path_to_save, \"infer_building\", \"convergence_plot_all.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    #if amro2title(amro) == \"MSSA\":\n",
    "    #    plt.show()\n",
    "    #else:\n",
    "    #    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
