{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir           = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data_metapop import create_population_data, create_time_transfers\n",
    "\n",
    "path_to_ward_counts = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"counts_ward.csv\" )\n",
    "path_to_ward_transf = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"transfers_ward.csv\" )\n",
    "\n",
    "A_df, D_df, H_df, tests_df, Hmean_df = create_population_data(path_to_ward_counts)\n",
    "\n",
    "num_wards  = len(Hmean_df)\n",
    "ward_names = list(Hmean_df.index)\n",
    "M_df       = create_time_transfers(path_to_ward_transf, num_wards=num_wards, ward_names=ward_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "wardid2buildingid            = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "ward2buildingid             =  {row.ward: row.buidling_id for i, row in ward_names_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inferences not adjusting the state space, as with the ABM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "from ifeakf import ifeakf\n",
    "\n",
    "\n",
    "def create_obs_building_amro(amro, model_settings, path_to_data, resample=\"W-Sun\"):\n",
    "    k                     = model_settings[\"k\"]\n",
    "    amro_df               = pd.read_csv(path_to_data, parse_dates=[\"date\"]).drop(columns=[\"Unnamed: 0\"])\n",
    "    amro_df               = amro_df[amro_df[\"amro\"]==amro]\n",
    "\n",
    "    amro_df[\"buildingid\"] = amro_df[\"ward_total\"].map(ward2buildingid)\n",
    "    amro_df               = amro_df.groupby([\"date\", \"buildingid\"]).sum(numeric_only=True).unstack([1]).resample(resample).sum(numeric_only=True).stack().reset_index()\n",
    "    amro_df[\"obs_name\"]   = amro_df[\"buildingid\"].map({i: f\"y{i+1}\" for i in range(k)})\n",
    "    amro_df               = pd.pivot(amro_df, index=\"date\", columns=\"obs_name\", values=\"num_positives\").reset_index()\n",
    "    for i in range(k):\n",
    "        amro_df['oev'+str(i+1)] = 1 +(0.2 * amro_df['y'+str(i+1)].values)**2\n",
    "    amro_df = amro_df.set_index(\"date\")\n",
    "    return amro_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_inference_amro(f, f0, g, obs_df, model_settings, if_settings, id_run=0, path_to_save=None):\n",
    "\n",
    "    ρmin              = 0.01 # test sensitivity minimum\n",
    "    ρmax              = 0.2  # test sensitivity maximum\n",
    "    βmin              = 0.00 # transmission rate minimum\n",
    "    βmax              = 0.5  # transmission rate maximum\n",
    "\n",
    "    state_space_range = model_settings[\"state_space_range\"]\n",
    "    parameters_range  = np.array([[ρmin, ρmax],    [βmin, βmax]])\n",
    "    σ_perturb         = np.array([(ρmax - ρmin)/4, (βmax - βmin)/4]) # (i hve the gut feeling that 0.25 is too large)\n",
    "\n",
    "    θmle, θpost = ifeakf(process_model                = f,\n",
    "                            state_space_initial_guess = f0,\n",
    "                            observational_model       = g,\n",
    "                            observations_df           = obs_df,\n",
    "                            parameters_range          = parameters_range,\n",
    "                            state_space_range         = state_space_range,\n",
    "                            model_settings            = model_settings,\n",
    "                            if_settings               = if_settings,\n",
    "                            perturbation              = σ_perturb)\n",
    "\n",
    "    np.savez_compressed(os.path.join(path_to_save, f\"{str(id_run).zfill(3)}posterior.npz\"),\n",
    "                                    mle           = θmle,\n",
    "                                    posterior     = θpost)\n",
    "\n",
    "    ρ_df = create_df_response(θpost[0, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "    β_df = create_df_response(θpost[1, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "\n",
    "    p_dfs             = [ρ_df, β_df]\n",
    "    param_label       = [\"ρ\", \"β\"]\n",
    "    parameters_range  = np.array([[ρmin, ρmax], [βmin, βmax]])\n",
    "    convergence_plot(θmle, p_dfs, parameters_range, param_label,\n",
    "                        path_to_save=os.path.join(path_to_save, f\"{str(id_run).zfill(3)}convergence.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import process_metapop, observe_metapop_cluster, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "from utils_local.misc import amro2cute\n",
    "\n",
    "delta = 1/120  # decolonization rate\n",
    "A     = A_df.to_numpy()\n",
    "D     = D_df.to_numpy()\n",
    "H     = H_df.to_numpy()\n",
    "M     = M_df\n",
    "tests = tests_df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running IF-EAKF for amro:  E. coli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:43<07:00, 17.53s/it]"
     ]
    }
   ],
   "source": [
    "from models import process_metapop, observe_metapop_cluster, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "from utils_data_metapop import empirical_prevalence\n",
    "from utils_local.misc import amro2cute\n",
    "\n",
    "#### create scenarios ####\n",
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "from utils_local.misc import amro2title\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],       # importation and transmission rate\n",
    "    \"p\"           : 2,                # number of parameters\n",
    "    \"dt\"          : 1,                # time step\n",
    "    \"m\"           : 300,              # number of ensembles\n",
    "    \"stochastic\"  : True              # is stochastic\n",
    "    }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "num_pop          = num_wards\n",
    "\n",
    "model_settings[\"n\"]           = 3 * num_pop            # number of state variables / dimension of the state space\n",
    "model_settings[\"T\"]           = len(dates_simulation)  # time to run\n",
    "model_settings[\"num_pop\"]     = num_pop\n",
    "model_settings[\"dates\"]       = dates_simulation\n",
    "model_settings[\"num_build\"]   = len(np.unique(list(wardid2buildingid.values())))\n",
    "model_settings[\"k\"]           = model_settings[\"num_build\"] # observing at the building aggregation\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "id_run                            = 0\n",
    "\n",
    "path_to_amro = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" )\n",
    "\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "\n",
    "    obs_df       = create_obs_building_amro(amro, model_settings, path_to_amro, resample=\"W-Sun\")\n",
    "    path_to_save = os.path.join(results2_dir, \"amro_inferences\", \"metapopulation\", f\"{amro2cute(amro)}\")\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    gamma        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    path_to_samples = os.path.join(path_to_save, \"no_adjust_state_space\")\n",
    "    os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "    if os.path.isfile(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\")):\n",
    "        continue\n",
    "\n",
    "    max_total_pop     = np.max(H.sum(axis=0))\n",
    "    model_settings[\"state_space_range\"] = np.array([0, max_total_pop])\n",
    "\n",
    "    init_state  = lambda θ:  init_metapop(N0               = H[:, 0],\n",
    "                                            c0             = gamma,\n",
    "                                            model_settings = model_settings)\n",
    "\n",
    "    process  = lambda t, x, θ: process_metapop(t, x,\n",
    "                                                gamma = gamma * np.ones(model_settings[\"m\"]),\n",
    "                                                beta  = θ[1, :],\n",
    "                                                delta = delta,\n",
    "                                                Nmean = np.expand_dims(Hmean_df, -1),\n",
    "                                                N     = H[:, [t]],\n",
    "                                                A     = A[:, [t]],\n",
    "                                                D     = D[:, [t]],\n",
    "                                                M     = M[:, :, t])\n",
    "\n",
    "    obs_model = lambda t, x, θ: observe_metapop_cluster(t, x,\n",
    "                                                    rho            = θ[0, :],\n",
    "                                                    N              = H[:, [t]],\n",
    "                                                    num_tests      = tests[:, [t]],\n",
    "                                                    model_settings = model_settings,\n",
    "                                                    ward2cluster   = wardid2buildingid)\n",
    "\n",
    "    run_inference_amro(f               = process,\n",
    "                        f0             = init_state,\n",
    "                        g              = obs_model,\n",
    "                        obs_df         = obs_df,\n",
    "                        model_settings = model_settings,\n",
    "                        if_settings    = if_settings,\n",
    "                        id_run         = 0,\n",
    "                        path_to_save   = path_to_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pompjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
