{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as onp\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "\n",
    "COLOR_LIST1 = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_88008/937339943.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_88008/937339943.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_diag_df[\"cluster\"][cluster_diag_df.cluster>=6] = 6\n"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df               = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"] = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df               = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id  = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id = {ward_name: id for id, ward_name in enumerate(movement_df.ward_total.unique())}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "cluster_diag_df              = pd.read_csv(os.path.join(\"..\", \"data\", \"infomap_nondiag.csv\"), sep=\" \").rename(columns={\"node_id\": \"ward_id\"})\n",
    "cluster_diag_df[\"ward_name\"] = cluster_diag_df[\"ward_id\"].map(id2ward)\n",
    "cluster_diag_df[\"cluster\"]   = cluster_diag_df.apply(lambda x: int(str(x.path).split(\":\")[0]), axis=1)\n",
    "cluster_diag_df              = cluster_diag_df[[\"cluster\", \"ward_id\", \"ward_name\"]].sort_values(by=\"cluster\")\n",
    "cluster_diag_df['num_wards'] = cluster_diag_df[\"cluster\"].apply(lambda x: onp.sum(cluster_diag_df[\"cluster\"] == x))\n",
    "\n",
    "cluster_diag_df[\"cluster\"][cluster_diag_df.cluster>=6] = 6\n",
    "cluster_diag_df[\"cluster\"] = cluster_diag_df[\"cluster\"].map(lambda x: int(x-1))\n",
    "\n",
    "cluster_diag_df['num_wards']                           = cluster_diag_df[\"cluster\"].apply(lambda x: onp.sum(cluster_diag_df[\"cluster\"] == x))\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "wardid2cluster         = dict(zip(cluster_diag_df[\"ward_id\"], cluster_diag_df[\"cluster\"]))\n",
    "movement_df[\"cluster\"] = movement_df[\"ward_id\"].map( wardid2cluster )\n",
    "movement_df[\"cluster\"] = movement_df[\"cluster\"].fillna(cluster_diag_df.cluster.max())\n",
    "movement_df[\"cluster\"] = movement_df[\"cluster\"].map(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient:\n",
    "    susceptible = 0\n",
    "    colonized   = 1\n",
    "\n",
    "class Observed:\n",
    "    no  = 0\n",
    "    yes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amr_abm(t, agents_state, gamma, beta, alpha, movement, ward2size, Np):\n",
    "    \"\"\" Agent based model tracking colonized and susceptible patients with pre-defined movement patterns.\n",
    "\n",
    "    Args:\n",
    "        agents_state : agent state. {0: Patient.susceptible, 1: Patient.colonized}  Size: (n_patients)\n",
    "        movement     : pd.Dataframe with patient locations and culture information.\n",
    "        parameters   : dictionary of parameters, contains importation rate (gamma), nosocomial transmission rate (beta),\n",
    "                        effective sensitivity (ro), and decolonization rate (alpha)\n",
    "    \"\"\"\n",
    "    agents_state = onp.array(agents_state)\n",
    "    _, m = agents_state.shape\n",
    "\n",
    "    γ   = gamma            # importation rate.\n",
    "    β   = beta             # nosocomial transmission rate.\n",
    "    α   = alpha            # decolonization rate.\n",
    "    Np  = Np               # number of patients\n",
    "\n",
    "    # Decolonize patients according to. P(C2S) = α\n",
    "    #agents_state.at[:].set(np.maximum(agents_state - agents_state * (random.uniform(key=key, shape=(Np, )) < α), 0))\n",
    "    #agents_state = agents_state - agents_state * (onp.random.uniform(size=(Np, )) < α)\n",
    "    p_update = agents_state.copy()\n",
    "    p_update = Patient.susceptible * (agents_state * onp.random.random(size=(Np, m)) <= α)\n",
    "\n",
    "    # import patients.\n",
    "    new_patients = movement[movement[\"first_day\"]==1][\"mrn_id\"].values\n",
    "    if new_patients.shape[0] > 0:\n",
    "        # P(S2C) = \\gamma - Probability of colonization given importation.\n",
    "        p_update[new_patients, :] = Patient.colonized * (onp.random.random(size=(new_patients.shape[0], m)) <= γ)\n",
    "\n",
    "    # Compute force of infection for each ward.\n",
    "    for i, ward_id in enumerate(movement[\"ward_id\"].unique()):\n",
    "        patients_ward = movement[movement[\"ward_id\"]==ward_id][\"mrn_id\"].values\n",
    "\n",
    "        # λ_i = β  * C / N  - Force of infection for ward i.\n",
    "        λ_i = β * onp.sum(p_update[patients_ward, :]==Patient.colonized) / ward2size[ward_id]\n",
    "\n",
    "        # P(C2S)_i = λ_i, we add the state but if already colonized the state would be 2 so we clip it to 1.\n",
    "        p_update[patients_ward, :] = p_update[patients_ward, :] + Patient.colonized * (onp.random.random(size=(patients_ward.shape[0], m)) <= λ_i)\n",
    "    p_update = onp.clip(p_update, 0, 1)\n",
    "    return p_update\n",
    "\n",
    "def observe_cluster(t, patients_state, movement, rho, Nc):\n",
    "    _, m           = patients_state.shape\n",
    "\n",
    "    ρ              = rho # effective sensitivity.\n",
    "    Nc             = Nc  # number of clusters\n",
    "\n",
    "    cluster_positive  = onp.zeros((Nc, m))\n",
    "    p_test            = Observed.yes * (onp.random.random(size=(patients_state.shape[0], m)) <= patients_state * ρ)\n",
    "\n",
    "    for i, cluster in enumerate(movement[\"cluster\"].unique()):\n",
    "        patients_test_ward            = movement.query(f\"cluster=={cluster} and test==True\")[\"mrn_id\"].values\n",
    "        cluster_positive[cluster,  :] = onp.sum(p_test[patients_test_ward, :]    == Observed.yes, axis=0)\n",
    "    return cluster_positive\n",
    "\n",
    "def f0(parameters, model_settings):\n",
    "    \"\"\" Initial state of the model.\n",
    "    \"\"\"\n",
    "    Np = parameters[\"Np\"]     # number of patients.\n",
    "    m  = model_settings[\"m\"]  # number of ensembles.\n",
    "\n",
    "    patient_state = onp.zeros((Np, m))\n",
    "    return patient_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_scenario(gamma, beta, rho, alpha, data_movement, model_settings):\n",
    "\n",
    "    dates_simulation = pd.to_datetime(onp.sort(data_movement.date.unique()))\n",
    "\n",
    "    θ = onp.array([[beta], [rho]]) * onp.ones((model_settings[\"p\"], model_settings[\"m\"]))\n",
    "    x = onp.zeros((model_settings[\"n\"], model_settings[\"m\"]))\n",
    "\n",
    "    f0_if  = lambda θ:       amr_abm(0, x, gamma, θ[0, :], alpha, movement_df[movement_df[\"date\"]==dates_simulation[0]], ward2size, model_settings[\"n\"])\n",
    "    f_if   = lambda t, x, θ: amr_abm(t, x, gamma, θ[0, :], alpha, movement_df[movement_df[\"date\"]==dates_simulation[t]], ward2size, model_settings[\"n\"])\n",
    "    g_if   = lambda t, x, θ: observe_cluster(t, x, movement_df[movement_df[\"date\"]==dates_simulation[t]], θ[1, :], Nc=model_settings[\"k\"])\n",
    "\n",
    "    # init state space\n",
    "    x = f0_if(θ)\n",
    "\n",
    "    observations          = onp.full((len(dates_simulation), model_settings[\"k\"], model_settings[\"m\"]), onp.nan)\n",
    "    observations[0, :, :] = g_if(0, x, θ)\n",
    "\n",
    "    for t, date in tqdm.tqdm(enumerate(dates_simulation[1:])):\n",
    "        x                       = f_if(t, x, θ)\n",
    "        observations[t+1, :, :] = g_if(t, x, θ)\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m./pompjax/pompjax\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyro\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontrib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mforecast\u001b[39;00m \u001b[39mimport\u001b[39;00m eval_crps\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meval\u001b[39;00m \u001b[39mimport\u001b[39;00m calibration\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_evals\u001b[39m(samples, obs, beta, rho,  name_var\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\"\"_summary_\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m        _type_: _description_\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eval'"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, \"./pompjax/pompjax\")\n",
    "\n",
    "from pyro.contrib.forecast import eval_crps\n",
    "from eval import calibration\n",
    "\n",
    "def compute_evals(samples, obs, beta, rho,  name_var=\"beta\"):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        samples (_type_): num_ensembles x num_times\n",
    "        obs (_type_): time series observation\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    cal_df = calibration.calibration(onp.expand_dims(samples.T, 0), onp.expand_dims(obs, 0), observation_index=0)\n",
    "    sc     = onp.mean(onp.abs(cal_df.quantiles.values-cal_df.proportion_inside.values))\n",
    "\n",
    "    df_response              = pd.DataFrame(columns=['crps', 'calibration_score', name_var, \"rho\"])\n",
    "    df_response['crps']      = [eval_crps(samples, obs)]\n",
    "    df_response[\"calibration_score\"] = sc\n",
    "    df_response[name_var]    = [beta]\n",
    "    df_response['rho']       = [rho]\n",
    "\n",
    "    return df_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def grid_search(amro, prevalence, movement_df, model_settings):\n",
    "    alpha = 1/120\n",
    "    gamma = prevalence\n",
    "\n",
    "\n",
    "    dates_resamp    = pd.date_range(start=\"2020-02-01\", end=\"2021-03-01\", freq=\"W-Sun\")\n",
    "\n",
    "    rho_search      = onp.arange(0.05, 0.2, 0.02)\n",
    "    beta_search     = onp.arange(0.005, 0.04+0.001, 0.005)\n",
    "\n",
    "    test_df         = movement_df.copy(); test_df = test_df[test_df[\"test\"]==1]\n",
    "    amro_df         = test_df.copy()\n",
    "    amro_df[\"keep\"] = amro_df[\"organism_name\"].apply(lambda x: amro in str(x))\n",
    "    amro_df         = amro_df[amro_df[\"keep\"]==True]\n",
    "    amro_df         = amro_df.groupby([\"date\", \"cluster\"]).sum()[[\"test\"]].unstack([1]).fillna(0).resample(\"W-Sun\").sum()\n",
    "    amro_df         = amro_df.xs(\"test\", axis=1, drop_level=True)\n",
    "    amro_df         = amro_df.sum(axis=1)\n",
    "    amro_df         = amro_df.reindex(dates_resamp, fill_value=0)\n",
    "\n",
    "    # sum across clusters\n",
    "    obs_amro  = amro_df.values\n",
    "\n",
    "    metric_df = pd.DataFrame()\n",
    "    for rho in rho_search:\n",
    "        for beta in beta_search:\n",
    "            observations       = simulate_scenario(gamma, beta, rho, alpha, movement_df, model_settings)\n",
    "            observations       = onp.sum(observations, axis=1)\n",
    "            sim_df             = pd.DataFrame(columns=[\"date\",\"ens_id\", \"values\", \"scenario\"])\n",
    "            sim_df[\"values\"]   = observations.flatten()\n",
    "            sim_df[\"date\"]     = flatten_list([ [date]*model_settings[\"m\"]  for date in  list(model_settings[\"dates\"])])\n",
    "            sim_df[\"ens_id\"]   = list(range(model_settings[\"m\"] )) * len(model_settings[\"dates\"])\n",
    "            sim_df[\"rho\"]      = rho\n",
    "\n",
    "            samples_t  = sim_df.set_index([\"date\", \"ens_id\", \"rho\"]).unstack([1, 2]).resample(\"W-Sun\").sum().stack().stack().reset_index()\n",
    "            samples_t  = pd.pivot(data=samples_t, index=\"date\", columns=\"ens_id\", values=\"values\").to_numpy().T\n",
    "            samples_t  = torch.tensor(samples_t);  obs_t  = torch.tensor(list(obs_amro))\n",
    "\n",
    "            df_metrics = compute_evals(samples_t, obs_t, beta, rho)\n",
    "            metric_df  = pd.concat([metric_df, df_metrics])\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amro2cute(amro):\n",
    "    if amro == 'ESCHERICHIA COLI':\n",
    "        return \"e_coli\"\n",
    "    elif amro == 'KLEBSIELLA PNEUMONIAE':\n",
    "        return \"k_pneumoniae\"\n",
    "    elif amro==\"PSEUDOMONAS AERUGINOSA\":\n",
    "        return \"p_aeruginosa\"\n",
    "    elif amro==\"METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS\":\n",
    "        return \"mssa\"\n",
    "    elif amro==\"METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS\":\n",
    "        return \"mrsa\"\n",
    "    elif amro==\"STAPHYLOCOCCUS EPIDERMIDIS\":\n",
    "        return \"s_epidermidis\"\n",
    "    elif amro==\"ENTEROCOCCUS FAECALIS\":\n",
    "        return \"e_faecalis\"\n",
    "    elif amro==\"ENTEROCOCCUS FAECIUM\":\n",
    "        return \"e_faecium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amro_prevalence_df = pd.read_csv(\"data/amro_prevalence.csv\")\n",
    "\n",
    "model_settings          = {}\n",
    "model_settings[\"m\"]     = 100\n",
    "model_settings[\"p\"]     = 2\n",
    "model_settings[\"n\"]     = movement_df.mrn_id.unique().shape[0]\n",
    "model_settings[\"k\"]     = movement_df.cluster.unique().shape[0]\n",
    "model_settings[\"dates\"] = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "amro_search = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE', 'PSEUDOMONAS AERUGINOSA', 'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS', 'STAPHYLOCOCCUS EPIDERMIDIS', 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for amro in amro_search:\n",
    "    if os.path.isfile( os.path.join(\"..\", \"preliminary_results\", f\"crps_{amro2cute(amro)}.csv\") ):\n",
    "        continue\n",
    "    gamma        = amro_prevalence_df[amro_prevalence_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "    crps_amro_df = grid_search( amro, gamma, movement_df, model_settings )\n",
    "    crps_amro_df.to_csv( os.path.join(\"..\", \"preliminary_results\", f\"crps_{amro2cute(amro)}.csv\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pompjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
