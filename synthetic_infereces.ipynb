{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as onp\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import jax.numpy as np\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "\n",
    "COLOR_LIST1 = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient:\n",
    "    susceptible = 0\n",
    "    colonized   = 1\n",
    "\n",
    "class Observed:\n",
    "    no  = 0\n",
    "    yes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amr_abm(t, agents_state, gamma, beta, alpha, movement, ward2size, Np):\n",
    "    \"\"\" Agent based model tracking colonized and susceptible patients with pre-defined movement patterns.\n",
    "\n",
    "    Args:\n",
    "        agents_state : agent state. {0: Patient.susceptible, 1: Patient.colonized}  Size: (n_patients)\n",
    "        movement     : pd.Dataframe with patient locations and culture information.\n",
    "        parameters   : dictionary of parameters, contains importation rate (gamma), nosocomial transmission rate (beta),\n",
    "                        effective sensitivity (ro), and decolonization rate (alpha)\n",
    "    \"\"\"\n",
    "    agents_state = onp.array(agents_state)\n",
    "\n",
    "    γ   = gamma            # importation rate.\n",
    "    β   = beta             # nosocomial transmission rate.\n",
    "    α   = alpha            # decolonization rate.\n",
    "    Np  = Np               # number of patients\n",
    "\n",
    "    # Decolonize patients according to. P(C2S) = α\n",
    "    #agents_state.at[:].set(np.maximum(agents_state - agents_state * (random.uniform(key=key, shape=(Np, )) < α), 0))\n",
    "    #agents_state = agents_state - agents_state * (onp.random.uniform(size=(Np, )) < α)\n",
    "    p_update = agents_state.copy()\n",
    "    p_update = Patient.susceptible * (agents_state * onp.random.random(size=(Np, )) <= α)\n",
    "\n",
    "    # import patients.\n",
    "    new_patients = movement[movement[\"first_day\"]==1][\"mrn_id\"].values\n",
    "    if new_patients.shape[0] > 0:\n",
    "        # P(S2C) = \\gamma - Probability of colonization given importation.\n",
    "        #agents_state[new_patients] = Patient.colonized * (random.uniform(key=key, shape=(new_patients.shape[0], )) < γ)\n",
    "        p_update[new_patients] = Patient.colonized * (onp.random.random(size=(new_patients.shape[0], )) <= γ)\n",
    "\n",
    "    # Compute force of infection for each ward.\n",
    "    for i, ward_id in enumerate(movement[\"ward_id\"].unique()):\n",
    "        patients_ward = movement[movement[\"ward_id\"]==ward_id][\"mrn_id\"].values\n",
    "\n",
    "        # λ_i = β  * C / N  - Force of infection for ward i.\n",
    "        λ_i = β * onp.sum(p_update[patients_ward]==Patient.colonized) / ward2size[ward_id]\n",
    "\n",
    "        # P(C2S)_i = λ_i, we add the state but if already colonized the state would be 2 so we clip it to 1.\n",
    "        # agents_state[patients_ward] = Patient.colonized * np.minimum(agents_state[patients_ward] + random.uniform(key=key, shape=(patients_ward.shape[0], )) < λ_i, 1)\n",
    "\n",
    "        p_update[patients_ward] = p_update[patients_ward] + Patient.colonized * (onp.random.random(size=(patients_ward.shape[0], )) <= λ_i)\n",
    "    p_update = onp.clip(p_update, 0, 1)\n",
    "    return p_update\n",
    "\n",
    "\n",
    "def observe_cluster(t, patients_state, movement, rho, Nc):\n",
    "    _, m           = patients_state.shape\n",
    "\n",
    "    ρ              = rho # effective sensitivity.\n",
    "    Nc             = Nc  # number of clusters\n",
    "\n",
    "    cluster_positive  = onp.zeros((Nc, m))\n",
    "    p_test            = Observed.yes * (onp.random.random(size=(patients_state.shape[0], m)) <= patients_state * ρ)\n",
    "\n",
    "    for i, cluster in enumerate(movement[\"cluster\"].unique()):\n",
    "        patients_test_ward            = movement.query(f\"cluster=={cluster} and test==True\")[\"mrn_id\"].values\n",
    "        cluster_positive[cluster,  :] = onp.sum(p_test[patients_test_ward, :]    == Observed.yes, axis=0)\n",
    "\n",
    "    return cluster_positive\n",
    "\n",
    "\n",
    "def f0(parameters, model_settings):\n",
    "    \"\"\" Initial state of the model.\n",
    "    \"\"\"\n",
    "    Np = parameters[\"Np\"]     # number of patients.\n",
    "    m  = model_settings[\"m\"]  # number of ensembles.\n",
    "\n",
    "    patient_state = onp.zeros((Np, m))\n",
    "    return patient_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df               = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"] = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df               = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id  = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id = {ward_name: id for id, ward_name in enumerate(movement_df.ward_total.unique())}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###\n",
    "cluster_diag_df              = pd.read_csv(\"infomap_nondiag.csv\", sep=\" \").rename(columns={\"node_id\": \"ward_id\"})\n",
    "cluster_diag_df[\"ward_name\"] = cluster_diag_df[\"ward_id\"].map(id2ward)\n",
    "cluster_diag_df[\"cluster\"]   = cluster_diag_df.apply(lambda x: int(str(x.path).split(\":\")[0]), axis=1)\n",
    "cluster_diag_df              = cluster_diag_df[[\"cluster\", \"ward_id\", \"ward_name\"]].sort_values(by=\"cluster\")\n",
    "cluster_diag_df['num_wards'] = cluster_diag_df[\"cluster\"].apply(lambda x: onp.sum(cluster_diag_df[\"cluster\"] == x))\n",
    "\n",
    "\n",
    "cluster_diag_df[[\"cluster\", \"num_wards\"]].drop_duplicates(keep=\"first\").plot(kind     = \"bar\",\n",
    "                                                                            x         = \"cluster\",\n",
    "                                                                            y         = \"num_wards\",\n",
    "                                                                            facecolor = \"lightgray\",\n",
    "                                                                            edgecolor = \"black\",\n",
    "                                                                            figsize=(7.5, 5),\n",
    "                                                                            xlabel=\"Cluster\", ylabel=\"Number of wards\")\n",
    "\n",
    "\n",
    "cluster_diag_df[\"cluster\"][cluster_diag_df.cluster>=6] = 6\n",
    "cluster_diag_df[\"cluster\"] = cluster_diag_df[\"cluster\"].map(lambda x: int(x-1))\n",
    "\n",
    "\n",
    "cluster_diag_df['num_wards']                           = cluster_diag_df[\"cluster\"].apply(lambda x: onp.sum(cluster_diag_df[\"cluster\"] == x))\n",
    "\n",
    "cluster_diag_df[[\"cluster\", \"num_wards\"]].drop_duplicates(keep=\"first\").plot(kind     = \"bar\",\n",
    "                                                                            x         = \"cluster\",\n",
    "                                                                            y         = \"num_wards\",\n",
    "                                                                            facecolor = \"lightgray\",\n",
    "                                                                            edgecolor = \"black\",\n",
    "                                                                            figsize=(7.5, 5),\n",
    "                                                                            xlabel=\"Cluster\",\n",
    "                                                                            ylabel=\"Number of wards\")\n",
    "\n",
    "\n",
    "wardid2cluster         = dict(zip(cluster_diag_df[\"ward_id\"], cluster_diag_df[\"cluster\"]))\n",
    "movement_df[\"cluster\"] = movement_df[\"ward_id\"].map( wardid2cluster )\n",
    "movement_df[\"cluster\"] = movement_df[\"cluster\"].fillna(cluster_diag_df.cluster.max())\n",
    "movement_df[\"cluster\"] = movement_df[\"cluster\"].map(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./pompjax\")\n",
    "\n",
    "from pompjax import ifeakf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_settings = {\n",
    "    \"m\"           : 100,                                         # number of ensembles\n",
    "    \"p\"           : 2,                                           # number of parameters\n",
    "    \"k\"           : movement_df[\"cluster\"].unique().shape[0],    # number of observations\n",
    "    \"n\"           : 1,                                           # number of state variables / dimension of the state space\n",
    "    \"dt\"          : 1,                                           # time step\n",
    "    \"param_name\"  : [\"β\", \"γ\", \"ρ\"],                             # name of the parameters\n",
    "    \"dates\"       : dates_simulation                             # integration dates (for the process model) | date_{t+1}-date_t = dt\n",
    "    # \"param_truth\" : [beta_truth, gamma_truth, report_rate_truth] # true parameter values (not required - just for the example)\n",
    "    }\n",
    "\n",
    "if_settings = {\n",
    "   \"Nif\"                : 20,                           # number of iterations of the IF\n",
    "   \"type_cooling\"       : \"geometric\",                  # type of cooling schedule\n",
    "   \"shrinkage_factor\"   : 0.9,                          # shrinkage factor for the cooling schedule\n",
    "   \"inflation\"          : 1.01,                         # inflation factor for spreading the variance after the EAKF step\n",
    "   \"assimilation_dates\" : observation_df[\"date\"].values # assimilation dates (for the inference)\n",
    "}\n",
    "\n",
    "# amr_abm(agents_state, gamma, beta, alpha, movement, ward2size, parameters)\n",
    "\n",
    "# Function to be used for the ikeafk function.\n",
    "#amr_abm(t, x, agents_state, gamma, beta, alpha, movement, ward2size, parameters)\n",
    "\n",
    "\n",
    "\n",
    "gamma = 15/100\n",
    "alpha = 1/120\n",
    "Np    = movement_df.mrn_id.unique().shape[0]\n",
    "Nc    = movement_df.cluster.unique().shape[0]\n",
    "m     = model_settings[\"m\"]\n",
    "\n",
    "p_status = np.zeros((Np, m))\n",
    "\n",
    "f_if     = lambda t, x, θ: amr_abm(t, x, θ[0, :], alpha, movement_df[movement_df[\"date\"]==dates_simulation[t]], ward2size, Np)\n",
    "#observe_cluster(t, patients_state, movement, rho, Nc)\n",
    "g_if  = lambda t, x, θ: observe_cluster(t, x, movement_df[movement_df[\"date\"]==dates_simulation[t]], θ[1, :], Nc=model_settings[\"k\"])\n",
    "f0_if = lambda θ: amr_abm(p_status, θ[0, :], alpha, movement_df[movement_df[\"date\"]==dates_simulation[0]], ward2size, Np)\n",
    "\n",
    "βmin = 0.001\n",
    "βmax = 0.8\n",
    "\n",
    "ρmin = 1/100\n",
    "ρmax = 15/100\n",
    "\n",
    "state_space_range = np.array([0, 1])\n",
    "parameters_range  = np.array([[βmin, βmax],\n",
    "                              [ρmin, ρmax]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pompjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
