{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosdonkey06/conda/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from abm_utils import empirical_prevalence, simulate_abm, create_obs_infer\n",
    "from utils_local.misc import amro2title, amro2cute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from abm_utils import run_amro_synthetic\n",
    "from utils import create_df_response\n",
    "from ifeakf import ifeakf\n",
    "\n",
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(u, v, cov_u):\n",
    "    \"\"\" Mahalanobis distance between a distribution θhat and a point θtruth\n",
    "\n",
    "    Args:\n",
    "        u:     Mean of distribution U\n",
    "        v:     Point\n",
    "        cov_u: Covariance matrix of U\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return np.sqrt((v - u).T @ np.linalg.inv(cov_u) @ (v - u))\n",
    "\n",
    "def lin_reg(x, y):\n",
    "    y    = np.expand_dims(y, -1)\n",
    "    xreg = np.float64(np.concatenate([np.expand_dims(x, -1), np.ones_like(y)], axis=1))\n",
    "    p    = np.linalg.inv(xreg.T @ xreg) @ xreg.T @ y\n",
    "    x    = np.expand_dims(np.linspace(np.around(np.min(x),1), np.max(x), 100), -1)\n",
    "    x    = np.float64(np.concatenate([x, np.ones_like(x)], axis=1)).T\n",
    "\n",
    "    yhat = np.squeeze(p.T @ x)\n",
    "\n",
    "    return x[0,:], yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
      "<ipython-input-7-22d15ade080f>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "gammas_search = [0.25, 0.5]\n",
    "betas_search  = [0.01, 0.05, 0.1]\n",
    "rho_search    = [1/100, 5/100, 10/100, 18/100]\n",
    "\n",
    "idx_sce = 0\n",
    "scenarios_large_df = pd.DataFrame(columns=[\"scenario\", \"gamma\", \"beta\", \"rho\"])\n",
    "for g in gammas_search:\n",
    "    for b in betas_search:\n",
    "        for r in rho_search:\n",
    "            scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
    "            idx_sce += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8d12fd2d6739>:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Synthetic 1/24\r"
     ]
    }
   ],
   "source": [
    "from models import amr_abm, observe_cluster_individual\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 200,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "id_run                            = 0\n",
    "\n",
    "\n",
    "id_run      = 5 # 5 is inference with mean trajectory\n",
    "\n",
    "for idx_row, row in scenarios_large_df.iterrows():\n",
    "    path_to_samples = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"], \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "    if os.path.isfile(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\")):\n",
    "        continue\n",
    "\n",
    "    gamma = row[\"gamma\"]\n",
    "\n",
    "    print(f\"\\t Synthetic {idx_row+1}/{len(scenarios_large_df)}\", end=\"\\r\")\n",
    "    model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    if_settings[\"shrink_variance\"]    = False\n",
    "\n",
    "    alpha               = 1/120\n",
    "    init_state          = lambda θ: amr_abm(t = 0,\n",
    "                                            agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                            gamma          = gamma,\n",
    "                                            beta           = θ[1, :],\n",
    "                                            alpha          = alpha,\n",
    "                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                            ward2size      = ward2size,\n",
    "                                            model_settings = model_settings)\n",
    "\n",
    "    process       = lambda t, x, θ: amr_abm(t = t,\n",
    "                                            agents_state   = x,\n",
    "                                            gamma          = gamma,\n",
    "                                            beta           = θ[1, :],\n",
    "                                            alpha          = alpha,\n",
    "                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                            ward2size      = ward2size,\n",
    "                                            model_settings = model_settings)\n",
    "\n",
    "    obs_model = lambda t, x, θ: observe_cluster_individual(t = t,\n",
    "                                                            agents_state   = x,\n",
    "                                                            rho            = θ[0, :],\n",
    "                                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                            model_settings = model_settings)\n",
    "\n",
    "    run_amro_synthetic(f               = process,\n",
    "                        f0             = init_state,\n",
    "                        g              = obs_model,\n",
    "                        fsim           = simulate_abm,\n",
    "                        model_settings = model_settings,\n",
    "                        if_settings    = if_settings,\n",
    "                        id_run         = id_run,\n",
    "                        path_to_save   = path_to_samples,\n",
    "                        use_mean       = True #use mean observation for inference\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_run = 0\n",
    "distance_df = pd.DataFrame()\n",
    "for idx_row, row in scenarios_large_df.iterrows():\n",
    "\n",
    "    path_to_samples = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"], \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "    inference       = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "\n",
    "    θpost           = inference[\"posterior\"].mean(-2)[:, :, -1]\n",
    "    θtruth          = inference[\"teta_truth\"][:, [0]] # [p, 1], Truth (vector column)\n",
    "    ysim            = inference[\"observations\"]\n",
    "    yinfer          = ysim[:, :, inference[\"idx_infer\"]]\n",
    "    Cv              = np.cov(θpost)  # covariance matrix\n",
    "    θmean           = θpost.mean(-1, keepdims=True) # [p, 1], mean estimate (vector column)\n",
    "\n",
    "\n",
    "    dist_estimate = mahalanobis_distance(θmean, θtruth, Cv)\n",
    "    obs_df             = pd.DataFrame(columns=[\"obs\", \"mean_obs\", \"date\"])\n",
    "    obs_df[\"obs\"]      = yinfer.sum(-1).T\n",
    "    obs_df[\"mean_obs\"] = np.mean(ysim.sum(1), -1).T\n",
    "    obs_df[\"date\"]     = dates_simulation\n",
    "    obs_df = obs_df.set_index(\"date\").resample(\"W\").sum()\n",
    "    dist   = np.sqrt(np.sum((obs_df[\"obs\"] - obs_df[\"mean_obs\"])**2))\n",
    "\n",
    "    crps_dist = eval_crps(torch.tensor(ysim.sum(1).T), torch.tensor(yinfer.sum(-1).T))\n",
    "\n",
    "    df            = pd.DataFrame.from_dict({\n",
    "                                        \"scenario\": idx_row+1,\n",
    "                                        \"distance_estimate\": dist_estimate[0,0],\n",
    "                                        \"distance_obs\": crps_dist,\n",
    "                                        \"gamma\": row[\"gamma\"],\n",
    "                                        \"beta\":  row[\"beta\"],\n",
    "                                        \"rho\":   row[\"rho\"]}, orient=\"index\").T\n",
    "\n",
    "    distance_df = pd.concat([distance_df, df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5.2), sharex=False, sharey=False)\n",
    "\n",
    "x, ylin = lin_reg(distance_df.distance_obs, distance_df.distance_estimate)\n",
    "ax.plot(x, ylin, color=\"k\", linestyle=\"-\", label=\"All\", lw=2)\n",
    "\n",
    "colors = [\"mediumpurple\", \"darkred\"]\n",
    "\n",
    "for idx_g, gamma in enumerate(distance_df.gamma.unique()):\n",
    "    d_df = distance_df[distance_df.gamma==gamma]\n",
    "    ax.scatter(d_df.distance_obs, d_df.distance_estimate, color=colors[idx_g], marker=\"x\", s=50)\n",
    "    x, ylin = lin_reg(d_df.distance_obs, d_df.distance_estimate)\n",
    "    ax.plot(x, ylin, color=colors[idx_g], label=rf\"$\\gamma$={gamma}\", lw=2, ls=\"--\")\n",
    "\n",
    "ax.set_title(r\"$\\hat{\\theta}:$ Mean estimate, $\\theta_T:$ Truth, $C:$ Covariance estimate\"+\"\\n\"+\n",
    "            r\"D=$\\sqrt{\\left(\\hat{\\theta}-\\theta_T\\right)^TC^{-1}\\left(\\hat{{\\theta}}-\\theta_T\\right)}$\")\n",
    "ax.set_xlabel(r\"CRPS(Y, y$_{infer}$)\")\n",
    "ax.set_ylabel(\"D\")\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig(os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"distance_estimate_vs_crpsObs.png\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bf8145230181c80995331dcd2d89ae11d44661bbc56f5633064428c02daedd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
