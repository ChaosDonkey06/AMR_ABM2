{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir           = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min            = pd.to_datetime(\"2020-02-01\")\n",
    "date_max            = pd.to_datetime(\"2021-02-28\")\n",
    "\n",
    "dates_simulation = pd.date_range(start=date_min, end=date_max, freq=\"D\")\n",
    "\n",
    "\n",
    "adht_ward_df = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", \"counts_ward.csv\" ), parse_dates=['date'])\n",
    "\n",
    "\n",
    "adht_ward_df   = adht_ward_df[adht_ward_df.date.isin(dates_simulation)]\n",
    "#selected_ward = ['Allen Hospital', 'Harkness Pavilion', 'Milstein Hospital', 'Mschony', 'Presbyterian Hospital']\n",
    "\n",
    "A_df     = pd.pivot(adht_ward_df, index='ward', columns='date', values='num_admitted')\n",
    "D_df     = pd.pivot(adht_ward_df, index='ward', columns='date', values='num_discharged')\n",
    "H_df     = pd.pivot(adht_ward_df, index='ward', columns='date', values='num_hospitalized')\n",
    "tests_df = pd.pivot(adht_ward_df, index='ward', columns='date', values='num_tested')\n",
    "\n",
    "pop        = H_df.mean(axis=1)\n",
    "num_pop    = len(pop)\n",
    "ward_names = pop.index\n",
    "\n",
    "ward_num          = len(ward_names)\n",
    "\n",
    "ward_transfers_df = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", \"transfers_ward.csv\"), parse_dates=['date'])\n",
    "ward_transfers_df = ward_transfers_df[ward_transfers_df.date.isin(dates_simulation)]\n",
    "\n",
    "M_df = np.zeros((ward_num, ward_num, len(dates_simulation)+1))\n",
    "\n",
    "for i in range(ward_num):\n",
    "    ward_from = ward_names[i]\n",
    "    for j in range(ward_num):\n",
    "        ward_to      = ward_names[j]\n",
    "        transfers_ij = ward_transfers_df[(ward_transfers_df.ward_from==ward_from) & (ward_transfers_df.ward_to==ward_to)]\n",
    "\n",
    "        if(transfers_ij.shape[0] > 0) :\n",
    "            dates_ij                = transfers_ij.date.values\n",
    "            dates_ind               = np.where(np.in1d(dates_ij, dates_simulation))[0]\n",
    "            transfered              = transfers_ij.num_transfered.values\n",
    "            M_df[i, j, dates_ind-1] = transfered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import process_metapop, observe_metapop, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "\n",
    "if_settings = {\n",
    "   \"Nif\"                : 50,          # number of iterations of the IF\n",
    "   \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "   \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "   \"inflation\"          : 1.01,        # inflation factor for spreading the variance after the EAKF step\n",
    "}\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],   # importation and transmission rate\n",
    "    \"p\"           : 2,              # number of parameters\n",
    "    \"k\"           : num_pop,        # number of observations | We are just observing carriage\n",
    "    \"n\"           : 3*num_pop,      # number of state variables / dimension of the state space\n",
    "    \"dt\"          : 1,              # time step\n",
    "    \"T\"           : len(dates_simulation), # time to run\n",
    "    \"m\"           : 100,           # number of ensembles\n",
    "    \"stochastic\"  : True,           # is stochastic\n",
    "    \"num_pop\"     : num_pop,\n",
    "    \"dates\"       : dates_simulation\n",
    "    }\n",
    "\n",
    "p = model_settings[\"p\"]\n",
    "m = model_settings[\"m\"]\n",
    "T = model_settings[\"T\"]\n",
    "\n",
    "delta = 1/120  # decolonization rate\n",
    "\n",
    "A = A_df.to_numpy()\n",
    "D = D_df.to_numpy()\n",
    "H = H_df.to_numpy()\n",
    "M = M_df\n",
    "\n",
    "#tests = tests_df.to_numpy()\n",
    "tests = np.zeros((num_pop, T))\n",
    "tests = tests_df.to_numpy()\n",
    "\n",
    "# Process model for the ifeakf | model(x, gamma, beta, delta, rho, sigma, pop, m=1, stochastic=True)\n",
    "process_model_gamma = lambda t, x, θ, gamma : process_metapop(t, x,\n",
    "                                            gamma = gamma * np.ones(m),\n",
    "                                            beta  = θ[1, :],\n",
    "                                            delta = delta,\n",
    "                                            Nmean = np.expand_dims(pop, -1),\n",
    "                                            N     = H[:, [t]],\n",
    "                                            A     = A[:, [t]],\n",
    "                                            D     = D[:, [t]],\n",
    "                                            M     = M[:, :, t])\n",
    "\n",
    "# Observational model for the ifeakf |  g(t, x, rho)\n",
    "observational_model  = lambda t, x, θ: observe_metapop(t, x,\n",
    "                                                rho            = θ[0, :],\n",
    "                                                N              = H[:, [t]],\n",
    "                                                num_tests      = tests[:, [t]],\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "\n",
    "# f0 model for the ifeakf            | initial_condition(c0, pop=2000, m=300)\n",
    "initial_guess_x0_gamma  = lambda θ, gamma:  init_metapop(\n",
    "                                                N0             = H[:, 0],\n",
    "                                                c0             = gamma, # importation rate\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "\n",
    "ρmin = 0.01 # test sensitivity minimum\n",
    "ρmax = 0.5  # test sensitivity maximum\n",
    "\n",
    "βmin = 0.001 # transmission rate minimum\n",
    "βmax = 0.5   # transmission rate maximum\n",
    "\n",
    "max_total_pop     = np.max(H.sum(axis=0))\n",
    "state_space_range = np.array([0, max_total_pop])\n",
    "parameters_range  = np.array([[ρmin, ρmax],\n",
    "                              [βmin, βmax]])\n",
    "\n",
    "σ_perturb         = np.array([(ρmax - ρmin)   / 4,\n",
    "                                (βmax - βmin) / 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amro2cute(amro):\n",
    "    if amro == 'ESCHERICHIA COLI':\n",
    "        return \"e_coli\"\n",
    "    elif amro == 'KLEBSIELLA PNEUMONIAE':\n",
    "        return \"k_pneumoniae\"\n",
    "    elif amro==\"PSEUDOMONAS AERUGINOSA\":\n",
    "        return \"p_aeruginosa\"\n",
    "    elif amro==\"METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS\":\n",
    "        return \"mssa\"\n",
    "    elif amro==\"METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS\":\n",
    "        return \"mrsa\"\n",
    "    elif amro==\"STAPHYLOCOCCUS EPIDERMIDIS\":\n",
    "        return \"s_epidermidis\"\n",
    "    elif amro==\"ENTEROCOCCUS FAECALIS\":\n",
    "        return \"e_faecalis\"\n",
    "    elif amro==\"ENTEROCOCCUS FAECIUM\":\n",
    "        return \"e_faecium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosdonkey06/anaconda3/envs/pompjax/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../pompjax/pompjax/\")\n",
    "\n",
    "from pyro.contrib.forecast import eval_crps\n",
    "from eval import calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evals(samples, obs, beta, rho,  name_var=\"beta\"):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        samples: num_ensembles x num_times\n",
    "        obs:     time series observation\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with the continuos ranked probability score (crps) and the average calibration.\n",
    "    \"\"\"\n",
    "\n",
    "    cal_df = calibration.calibration(np.expand_dims(samples.T, 0), np.expand_dims(obs, 0), observation_index=0)\n",
    "    sc     = np.mean(np.abs(cal_df.quantiles.values-cal_df.proportion_inside.values))\n",
    "\n",
    "    df_response                      = pd.DataFrame(columns=['crps', 'calibration_score', name_var, \"rho\"])\n",
    "    df_response['crps']              = [eval_crps(samples, obs)]\n",
    "    df_response[\"calibration_score\"] = sc\n",
    "    df_response[name_var]            = [beta]\n",
    "    df_response['rho']               = [rho]\n",
    "    return df_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df               = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", \"patient_movement_2022-Nov.csv\"), parse_dates=['date'])\n",
    "patient_df               = patient_df.drop_duplicates(['date','mrn'])\n",
    "patient_df[\"ward_total\"] = patient_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "\n",
    "ward2id                  = {w: i for i, w in enumerate(patient_df[\"ward_total\"].index.values)}\n",
    "\n",
    "#duplicated_pos_tests = (patient_df[['mrn','organism_name']].duplicated() & ~patient_df['organism_name'].isnull())\n",
    "duplicated_pos_tests = (patient_df[['encounter_id','organism_name']].duplicated() & ~patient_df['organism_name'].isnull())\n",
    "\n",
    "patient_df.loc[duplicated_pos_tests,'test']          = 0\n",
    "patient_df.loc[duplicated_pos_tests,'organism_name'] = np.nan\n",
    "\n",
    "wards       = patient_df.ward_total.unique()\n",
    "amro_search = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE', 'PSEUDOMONAS AERUGINOSA', 'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS', 'STAPHYLOCOCCUS EPIDERMIDIS', 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "amro_search = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE', 'PSEUDOMONAS AERUGINOSA', 'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS', 'STAPHYLOCOCCUS EPIDERMIDIS', 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "amro             = amro_search[0]\n",
    "amro_prev_df     = pd.read_csv(os.path.join(\"..\", \"data\", \"amro_prevalence.csv\"))\n",
    "gamma            = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "amro_df          = pd.read_csv( os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" ), parse_dates=[\"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combination(arr1, arr2):\n",
    "    a = []\n",
    "    for a1 in arr1:\n",
    "        for a2 in arr2:\n",
    "            a.append([a1, a2])\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "ρmin    = 1/100\n",
    "ρmax    = 20/100\n",
    "\n",
    "βmin    = 0.01\n",
    "βmax    = 0.5\n",
    "\n",
    "ρ_search = np.arange(ρmin, ρmax+1/100, 1/100)\n",
    "β_search = np.arange(βmin, βmax+0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def grid_search(amro, gamma, amro_df, model_settings, previous_search=None):\n",
    "    amro_df  = amro_df[amro_df.amro==amro].groupby(\"date\").sum(numeric_only=True).reset_index()\n",
    "    obs_amro = amro_df.set_index(\"date\").resample(\"W-Sun\").sum(numeric_only=True)[\"value\"].values[4:]\n",
    "\n",
    "    process_model    = lambda t, x, θ : process_model_gamma(t, x, θ, gamma=gamma)\n",
    "    initial_guess_x0 = lambda θ:  initial_guess_x0_gamma(θ, gamma=gamma)\n",
    "\n",
    "    ρmin    = 1/100\n",
    "    ρmax    = 20/100\n",
    "\n",
    "    βmin    = 0.01\n",
    "    βmax    = 0.5\n",
    "\n",
    "    ρ_search = np.linspace(ρmin, ρmax, 1/100)\n",
    "    β_search = np.linspace(βmin, βmax, 0.01)\n",
    "\n",
    "    psearch  = generate_combination(ρ_search, β_search)\n",
    "\n",
    "    metric_df = []\n",
    "    for idx_s, p in tqdm(enumerate(psearch)):\n",
    "        ρsim = p[0]\n",
    "        βsim = p[1]\n",
    "\n",
    "        θsim               = np.array([[ρsim], [βsim]]) * np.ones((2, model_settings[\"m\"]))\n",
    "        y_sim              = simulate_metapop_observations(process_model, observational_model, initial_guess_x0, θsim, model_settings)\n",
    "        observations       = np.sum(y_sim, axis=1)\n",
    "        sim_df             = pd.DataFrame(columns=[\"date\", \"ens_id\", \"values\", \"scenario\"])\n",
    "        sim_df[\"values\"]   = observations.flatten()\n",
    "        sim_df[\"date\"]     = flatten_list([ [date]*model_settings[\"m\"]  for date in  list(model_settings[\"dates\"])])\n",
    "        sim_df[\"ens_id\"]   = list(range(model_settings[\"m\"] )) * len(model_settings[\"dates\"])\n",
    "        sim_df[\"rho\"]      = ρsim\n",
    "\n",
    "        samples_t  = sim_df.set_index([\"date\", \"ens_id\", \"rho\"]).unstack([1, 2]).resample(\"W-Sun\").sum(numeric_only=True).stack().stack().reset_index()\n",
    "        samples_t  = pd.pivot(data=samples_t, index=\"date\", columns=\"ens_id\", values=\"values\").to_numpy()\n",
    "        samples_t  = samples_t[4:, :].T\n",
    "        samples_t  = torch.tensor(samples_t);  obs_t  = torch.tensor(list(obs_amro))\n",
    "        df_metrics = compute_evals(samples_t, obs_t, βsim, ρsim)\n",
    "        metric_df.append(df_metrics)\n",
    "    return pd.concat(metric_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "656it [59:08,  5.70s/it]"
     ]
    }
   ],
   "source": [
    "amro_prev_df     = pd.read_csv(os.path.join(\"..\", \"data\", \"amro_prevalence.csv\"))\n",
    "amro_df = pd.read_csv( os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" ), parse_dates=[\"date\"])\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"grid search for \", amro, \" ...\")\n",
    "    gamma        = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "    crps_amro_df = grid_search(amro, gamma, amro_df, model_settings, previous_search=None)\n",
    "    crps_amro_df.to_csv( os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "amro_search = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE', 'PSEUDOMONAS AERUGINOSA', 'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS', 'STAPHYLOCOCCUS EPIDERMIDIS', 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(12, 5), sharey=True, sharex=True)\n",
    "\n",
    "for idx_axi, axi in enumerate(ax.flatten()):\n",
    "    amro         = amro_search[idx_axi]\n",
    "    grid_amro_df = pd.read_csv(  os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\") )\n",
    "\n",
    "    hm_crps_df = grid_amro_df.pivot(index='beta', columns='rho', values='crps')\n",
    "    sns.heatmap(ax=axi, data=hm_crps_df, cmap='Reds')\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "    axi.set_title(\". \".join(amro2cute(amro).split(\"_\")).capitalize())\n",
    "\n",
    "ax[0, 0].set_ylabel(r'$\\beta$')\n",
    "ax[1, 0].set_ylabel(r'$\\beta$')\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1, i].set_xlabel(r'$\\rho$')\n",
    "\n",
    "fig.suptitle(\"Metapopulation CRPS landscapes\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(12, 5), sharey=True, sharex=True)\n",
    "\n",
    "for idx_axi, axi in enumerate(ax.flatten()):\n",
    "    amro         = amro_search[idx_axi]\n",
    "    grid_amro_df = pd.read_csv(  os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\") )\n",
    "\n",
    "    hm_cov_df  = grid_amro_df.pivot(index='beta', columns='rho', values='calibration_score')\n",
    "    sns.heatmap(ax=axi, data=hm_cov_df, cmap='Reds')\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "    axi.set_title(\". \".join(amro2cute(amro).split(\"_\")).capitalize())\n",
    "\n",
    "ax[0, 0].set_ylabel(r'$\\beta$')\n",
    "ax[1, 0].set_ylabel(r'$\\beta$')\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1, i].set_xlabel(r'$\\rho$')\n",
    "\n",
    "fig.suptitle(\"Metapopulation average calibration landscapes\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
