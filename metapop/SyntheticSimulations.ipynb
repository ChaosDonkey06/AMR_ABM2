{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "\n",
    "# Plot Tong's default setting\n",
    "SMALL_SIZE  = 15\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE, family='sans-serif', serif='Arial')          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\"\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "plt.rc('text')\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "def format_axis(ax, week=True):\n",
    "    ax.tick_params(which='both', axis='x', labelrotation=90)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%y'))\n",
    "    if week:\n",
    "        ax.xaxis.set_minor_locator(mdates.WeekdayLocator())\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "sys.path.insert(0,\"../\")\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir           = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population_data(path_to_file, date_start=pd.to_datetime(\"2020-02-01\"), date_end=pd.to_datetime(\"2021-02-28\")):\n",
    "\n",
    "    dates_simulation = pd.date_range(start=date_start, end=date_end, freq=\"D\")\n",
    "\n",
    "    data_df  = pd.read_csv( path_to_file, parse_dates=['date'])\n",
    "    data_df  = data_df[data_df.date.isin(dates_simulation)]\n",
    "    A_df     = pd.pivot(data_df, index='ward', columns='date', values='num_admitted')\n",
    "    D_df     = pd.pivot(data_df, index='ward', columns='date', values='num_discharged')\n",
    "    H_df     = pd.pivot(data_df, index='ward', columns='date', values='num_hospitalized')\n",
    "    tests_df = pd.pivot(data_df, index='ward', columns='date', values='num_tested')\n",
    "    Hmean_df = H_df.mean(axis=1)\n",
    "\n",
    "    return A_df, D_df, H_df, tests_df, Hmean_df\n",
    "\n",
    "def create_time_transfers(path_to_file, num_wards, ward_names, date_start=pd.to_datetime(\"2020-02-01\"), date_end=pd.to_datetime(\"2021-02-28\")):\n",
    "\n",
    "    dates_simulation = pd.date_range(start=date_start, end=date_end, freq=\"D\")\n",
    "    transfers_df     = pd.read_csv(path_to_file, parse_dates=['date'])\n",
    "    transfers_df     = transfers_df[transfers_df.date.isin(dates_simulation)]\n",
    "    M_df             = np.zeros((num_wards, num_wards, len(dates_simulation)+1))\n",
    "\n",
    "    for i in range(num_wards):\n",
    "        ward_from = ward_names[i]\n",
    "        for j in range(num_wards):\n",
    "            ward_to      = ward_names[j]\n",
    "            transfers_ij = transfers_df[(transfers_df.ward_from==ward_from) & (transfers_df.ward_to==ward_to)]\n",
    "\n",
    "            if(transfers_ij.shape[0] > 0) :\n",
    "                dates_ij                = transfers_ij.date.values\n",
    "                dates_ind               = np.where(np.in1d(dates_ij, dates_simulation))[0]\n",
    "                transfered              = transfers_ij.num_transfered.values\n",
    "                M_df[i, j, dates_ind-1] = transfered\n",
    "\n",
    "    return M_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ward_counts = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"counts_ward.csv\" )\n",
    "path_to_ward_transf = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"transfers_ward.csv\" )\n",
    "\n",
    "\n",
    "A_df, D_df, H_df, tests_df, Hmean_df = create_population_data(path_to_ward_counts)\n",
    "\n",
    "num_wards  = len(Hmean_df)\n",
    "ward_names = list(Hmean_df.index)\n",
    "M_df       = create_time_transfers(path_to_ward_transf, num_wards=num_wards, ward_names=ward_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we want to choose synthetic scenarios that overall reproduce the synthetic observations, so we are going to use the stuff above (in the GridSearch) to sample from the parameter space and create the synthetic scenarios randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def return_score_cutoff(score, cut_off_prob=0.05):\n",
    "    freq, score = np.histogram(score, bins=100, density=True)\n",
    "    freq_cum    = np.cumsum(freq); freq_cum = freq_cum/freq_cum[-1]\n",
    "    score       = score[1:]\n",
    "    f_cum       = UnivariateSpline(score, freq_cum, s=0.001)\n",
    "    sc_range    = np.linspace(np.min(score), np.max(score), 1000)\n",
    "    score_cut   = sc_range[np.argmin(np.abs(f_cum(sc_range) * 100 - cut_off_prob*100))]\n",
    "    return score_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "wardid2buildingid            = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import process_metapop, observe_metapop, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "from misc import amro2cute\n",
    "\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "num_pop          = num_wards\n",
    "\n",
    "if_settings = {\n",
    "   \"Nif\"                : 50,          # number of iterations of the IF\n",
    "   \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "   \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "   \"inflation\"          : 1.01,        # inflation factor for spreading the variance after the EAKF step\n",
    "}\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],            # importation and transmission rate\n",
    "    \"p\"           : 2,                     # number of parameters\n",
    "    \"k\"           : num_pop,               # number of observations | We are just observing carriage\n",
    "    \"n\"           : 3*num_pop,             # number of state variables / dimension of the state space\n",
    "    \"dt\"          : 1,                     # time step\n",
    "    \"T\"           : len(dates_simulation), # time to run\n",
    "    \"m\"           : 300,                   # number of ensembles\n",
    "    \"stochastic\"  : True,                  # is stochastic\n",
    "    \"num_pop\"     : num_pop,\n",
    "    \"dates\"       : dates_simulation\n",
    "    }\n",
    "\n",
    "delta = 1/120  # decolonization rate\n",
    "\n",
    "A     = A_df.to_numpy()\n",
    "D     = D_df.to_numpy()\n",
    "H     = H_df.to_numpy()\n",
    "M     = M_df\n",
    "tests = tests_df.to_numpy()\n",
    "\n",
    "# Process model for the ifeakf | model(x, gamma, beta, delta, rho, sigma, pop, m=1, stochastic=True)\n",
    "process_model_gamma = lambda t, x, θ, gamma : process_metapop(t, x,\n",
    "                                            gamma = gamma * np.ones(model_settings[\"m\"]),\n",
    "                                            beta  = θ[1, :],\n",
    "                                            delta = delta,\n",
    "                                            Nmean = np.expand_dims(Hmean_df, -1),\n",
    "                                            N     = H[:, [t]],\n",
    "                                            A     = A[:, [t]],\n",
    "                                            D     = D[:, [t]],\n",
    "                                            M     = M[:, :, t])\n",
    "\n",
    "# f0 model for the ifeakf            | initial_condition(c0, pop=2000, m=300)\n",
    "initial_guess_x0_gamma  = lambda θ, gamma:  init_metapop(\n",
    "                                                N0             = H[:, 0],\n",
    "                                                c0             = gamma, # importation rate\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "# Observational model for the ifeakf |  g(t, x, rho)\n",
    "observational_model  = lambda t, x, θ: observe_metapop(t, x,\n",
    "                                                rho            = θ[0, :],\n",
    "                                                N              = H[:, [t]],\n",
    "                                                num_tests      = tests[:, [t]],\n",
    "                                                model_settings = model_settings,\n",
    "                                                ward2cluster   = wardid2buildingid)\n",
    "\n",
    "def observe_metapop_cluster(t, x, N, rho, num_tests, ward2cluster):\n",
    "    \"\"\" Observational model\n",
    "        Args:\n",
    "            t (int):      Time\n",
    "            x (np.array): State space\n",
    "            rho (float):  Observation probability\n",
    "        Returns:\n",
    "            y (np.array): Observed carriers ~ Binomial(C, rho).\n",
    "    \"\"\"\n",
    "\n",
    "    m         = model_settings[\"m\"]\n",
    "    num_pop   = model_settings[\"num_pop\"]\n",
    "    num_build = model_settings[\"num_build\"]\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.clip(np.nan_to_num(x[0, :, :]/N), 0, 1)\n",
    "\n",
    "    observed_colonized = np.random.binomial(list(num_tests * np.ones((num_pop, m))), rho * c)  # Shape [num_pop, m]\n",
    "    # need to resample this to [num_buildings x m] (maybe using the same buildings that rami used)\n",
    "    obs_col_building = np.zeros((num_build, m))\n",
    "\n",
    "    for i in range(num_pop):\n",
    "        obs_col_building[ward2cluster[i], :] += observed_colonized[i, :]\n",
    "\n",
    "    return obs_col_building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_array(array, dict_agg):\n",
    "    \"\"\" Resample an array along a given axis.\n",
    "\n",
    "    Args:\n",
    "        array: _description_\n",
    "        axis_resample: _description_\n",
    "        dict_agg: mapping of the original array to the new array. e.g. if map across indicated axis is {0: 0, 1: 0, 2: 1, 3:1}\n",
    "                          idx agg could be that dict or a matrix [[0 0], [1 0], [2 1], [3 1]]]\n",
    "    \"\"\"\n",
    "\n",
    "    t    = array.shape[0]\n",
    "    m    = array.shape[-1]\n",
    "\n",
    "    mapA        = np.array(list(dict_agg.items()))\n",
    "    kold, knew  = np.max(mapA, axis=0)\n",
    "    xnew        = np.zeros((t, knew+1, m))\n",
    "    for ki in range(knew+1):\n",
    "        H                      = np.zeros((knew+1, kold+1))\n",
    "        H[:, mapA[:, 1] == ki] = 1\n",
    "        a = H @ array.transpose(0, 1, 2)\n",
    "        xnew[:, ki, :] = a[:, ki, :]\n",
    "\n",
    "    return xnew\n",
    "\n",
    "def resample_array2(array, dict_agg):\n",
    "    \"\"\" Resample an array along a given axis.\n",
    "\n",
    "    Args:\n",
    "        array: _description_\n",
    "        axis_resample: _description_\n",
    "        dict_agg: mapping of the original array to the new array. e.g. if map across indicated axis is {0: 0, 1: 0, 2: 1, 3:1}\n",
    "                          idx agg could be that dict or a matrix [[0 0], [1 0], [2 1], [3 1]]]\n",
    "    \"\"\"\n",
    "\n",
    "    t    = array.shape[0]\n",
    "    m    = array.shape[-1]\n",
    "\n",
    "    mapA        = np.array(list(dict_agg.items()))\n",
    "    kold, knew  = np.max(mapA, axis=0)\n",
    "    xnew        = np.zeros((t, knew+1, m))\n",
    "    for ki in range(kold+1):\n",
    "        xnew[:, dict_agg[ki], :] += array[:, ki, :]\n",
    "    return xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_prob = 5/100\n",
    "amro_prev_df = pd.read_csv(os.path.join(\"..\", \"data\", \"amro_prevalence.csv\"))\n",
    "\n",
    "\n",
    "amro         = \"ESCHERICHIA COLI\"\n",
    "gs_df        = pd.read_csv( os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\") ).drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "gamma        = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "\n",
    "sc_cutoff    = return_score_cutoff(gs_df.crps, cut_off_prob=cut_off_prob)\n",
    "gs_df        = gs_df[gs_df.crps <= sc_cutoff].reset_index(drop=True)\n",
    "scenarios_df = gs_df.copy()\n",
    "scenarios_df = scenarios_df.sample(n=10); scenarios_df = scenarios_df[[\"rho\", \"beta\", \"crps\", \"calibration_score\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "idx_row, row                  = next(scenarios_df.iterrows())\n",
    "model_settings[\"param_truth\"] = [row[\"rho\"], row[\"beta\"]]\n",
    "\n",
    "model_settings[\"num_build\"] = len(np.unique(list(wardid2buildingid.values())))\n",
    "model_settings[\"k\"]         = model_settings[\"num_build\"] # observing at that aggregation\n",
    "\n",
    "process_model        = lambda t, x, θ: process_model_gamma(t, x, θ, gamma=gamma)\n",
    "init_conditions      = lambda θ: initial_guess_x0_gamma(θ, gamma=gamma)\n",
    "observational_model  = lambda t, x, θ: observe_metapop_cluster(t, x,\n",
    "                                            N            = H[:, [t]],\n",
    "                                            rho          = θ[0, :],\n",
    "                                            num_tests    = tests[:, [t]],\n",
    "                                            ward2cluster = wardid2buildingid)\n",
    "\n",
    "θtruth = np.array([model_settings[\"param_truth\"]]).T * np.ones((model_settings[\"p\"], model_settings[\"m\"]))\n",
    "\n",
    "x_sim, y_sim = simulate_metapop(\n",
    "                process_model       = process_model,\n",
    "                observational_model = observational_model,\n",
    "                init_state          = init_conditions,\n",
    "                θsim                = θtruth,\n",
    "                model_settings      = model_settings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_df_response\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../pompjax/pompjax/\")\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia', 'Rest']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 7), sharex=True, sharey=False)\n",
    "for ix, ax in enumerate(axes.flatten()):\n",
    "    obs_df = create_df_response(y_sim[:, ix, :], time=len(model_settings[\"dates\"]), dates=model_settings[\"dates\"]).resample(\"W-Sun\").sum(numeric_only=True).reset_index()\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_95\"], obs_df[\"high_95\"], alpha=0.3, color=\"#0096ca\")\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_50\"], obs_df[\"high_50\"], alpha=0.5, color=\"#0096ca\")\n",
    "    ax.plot(obs_df[\"date\"], obs_df[\"median\"], color=\"#0096ca\", ls=\"-\", lw=2)\n",
    "    ax.text(0.05, 0.9, \"{}\".format(selected_buildings[ix].split(\"-\")[0]), transform=ax.transAxes, fontsize=14, fontweight='normal', va='top')\n",
    "    format_axis(ax)\n",
    "\n",
    "axes[-1, 0].set_xlabel(\"Date (week)\")\n",
    "axes[-1, 1].set_xlabel(\"Date (week)\")\n",
    "axes[-1, 2].set_xlabel(\"Date (week)\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col  = resample_array(x_sim[:, 0, :, :], wardid2buildingid)\n",
    "imp  = resample_array(x_sim[:, 1, :, :], wardid2buildingid)\n",
    "cnew = resample_array(x_sim[:, 2, :, :], wardid2buildingid)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 7), sharex=True, sharey=False)\n",
    "for ix, ax in enumerate(axes.flatten()):\n",
    "\n",
    "    obs_df = create_df_response(col[:, ix, :], time=len(model_settings[\"dates\"]), dates=model_settings[\"dates\"]).resample(\"W-Sun\").sum(numeric_only=True).reset_index()\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_95\"], obs_df[\"high_95\"], alpha=0.3, color=\"#0096ca\", label=\"Colonized\")\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_50\"], obs_df[\"high_50\"], alpha=0.5, color=\"#0096ca\")\n",
    "    ax.plot(obs_df[\"date\"], obs_df[\"median\"], color=\"#0096ca\", ls=\"-\", lw=1)\n",
    "\n",
    "    obs_df = create_df_response(imp[:, ix, :], time=len(model_settings[\"dates\"]), dates=model_settings[\"dates\"]).resample(\"W-Sun\").sum(numeric_only=True).reset_index()\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_95\"], obs_df[\"high_95\"], alpha=0.3, color=\"#ed0041\",  label=\"Importations\")\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_50\"], obs_df[\"high_50\"], alpha=0.5, color=\"#ed0041\")\n",
    "    ax.plot(obs_df[\"date\"], obs_df[\"median\"], color=\"#ed0041\", ls=\"-\", lw=1)\n",
    "\n",
    "    obs_df = create_df_response(cnew[:, ix, :], time=len(model_settings[\"dates\"]), dates=model_settings[\"dates\"]).resample(\"W-Sun\").sum(numeric_only=True).reset_index()\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_95\"], obs_df[\"high_95\"], alpha=0.3, color=\"#002d72\",  label=\"New colonizations\")\n",
    "    ax.fill_between(obs_df[\"date\"], obs_df[\"low_50\"], obs_df[\"high_50\"], alpha=0.5, color=\"#002d72\")\n",
    "    ax.plot(obs_df[\"date\"], obs_df[\"median\"], color=\"#002d72\", ls=\"-\", lw=1)\n",
    "\n",
    "    ax.text(0.05, 0.9, \"{}\".format(selected_buildings[ix].split(\"-\")[0]), transform=ax.transAxes, fontsize=14, fontweight='normal', va='top')\n",
    "    format_axis(ax)\n",
    "\n",
    "axes[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0.0, 1.2), ncol=3, frameon=False)\n",
    "axes[-1, 0].set_xlabel(\"Date (week)\")\n",
    "axes[-1, 1].set_xlabel(\"Date (week)\")\n",
    "axes[-1, 2].set_xlabel(\"Date (week)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  A_{k \\times T} =\n",
    "  \\left[ {\\begin{array}{ccccc}\n",
    "    x_1[1] & x_1[2] &  x_1[3] &\\cdots & x_1[T] \\\\\n",
    "    x_2[1] & x_2[2] &  x_2[3] &\\cdots & x_2[T] \\\\\n",
    "    \\vdots & \\vdots &  \\vdots  &\\ddots & \\vdots\\\\\n",
    "    x_k[1] & x_k[2] &  x_k[3] &\\cdots & x_k[T] \\\\\n",
    "  \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "for adding columns say for ex 1, 2 into a new matrix $B\\in [k_2, T]$\n",
    "$$B_k = x\\sum_{j\\in{{1,2}}} x_j[t]$$\n",
    "Which i think can be wrote as\n",
    "$A^T \\times   \\left[ {\\begin{array}{ccccc}\n",
    "    1 & 1 &  0 &\\cdots & 0 \\\\\n",
    "    1 & 1 &  0 &\\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots &  \\vdots  &\\ddots & \\vdots\\\\\n",
    "    1 & 1 &  0 &\\cdots & 0 \\\\\n",
    "  \\end{array} } \\right]$, where that second matrix has 1 vectors of size T in the position we want to resample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_sims = os.path.join(results2_dir, \"synthetic_sims\", \"metapopulation\", f\"{amro2cute(amro)}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
