{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from utils_local.misc import amro2title, amro2cute\n",
    "import matplotlib.ticker as mtick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\"):\n",
    "    amro_prev_df = pd.read_csv(path_to_prev)\n",
    "    gammas       = amro_prev_df[amro_prev_df.amro==amro][[\"prevalence_mean1\", \"prevalence_mean2\", \"prevalence_mean3\"]].values / 100\n",
    "    return np.squeeze(gammas)\n",
    "\n",
    "def simulate_abm(f, f0, g, θ, model_settings):\n",
    "    dates_simulation = model_settings[\"dates_simulation\"]\n",
    "\n",
    "    x                     = f0(θ)\n",
    "    observations          = np.full((len(dates_simulation), model_settings[\"k\"], model_settings[\"m\"]), np.nan)\n",
    "    observations[0, :, :] = g(0, x, θ)\n",
    "\n",
    "    for t, date in enumerate(dates_simulation[1:]):\n",
    "        x                       = f(t, x, θ)\n",
    "        observations[t+1, :, :] = g(t, x, θ)\n",
    "    return observations\n",
    "\n",
    "def create_obs_infer(obs_sim, idx_infer, dates, model_settings, resample=\"W-Sun\"):\n",
    "    # obs_sim \\in R^{[k x T x m]} as required by pompjax\n",
    "    infer_df = pd.DataFrame(index=dates)\n",
    "    for i in range(model_settings[\"k\"]) :\n",
    "        infer_df['y'+str(i+1)]   = obs_sim[i, :, idx_infer]\n",
    "        infer_df['oev'+str(i+1)] = 1 +(0.2 * infer_df['y'+str(i+1)].values)**2\n",
    "    infer_df                     = infer_df.resample(resample).sum()\n",
    "    infer_df.index.values[-1]    = model_settings[\"dates\"][-1]\n",
    "    return infer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/jp6xqkvn5wb6ddl1fn0bhs980000gn/T/ipykernel_92276/2265996033.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "ward2buildingid        =  {row.ward: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import amr_abm, observe_cluster_individual\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 200,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "id_run                            = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_obs_building_amro\n",
    "from infer_utils import run_amro_inference\n",
    "\n",
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS', 'METHICILLIN-RESISTANT STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_amro = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"amro_ward.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for amro in amro_search:\n",
    "\n",
    "    gammas       = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "    obs_df       = create_obs_building_amro(amro, model_settings, ward2buildingid, path_to_amro)\n",
    "    path_to_save = os.path.join(results2_dir, \"amro_inferences\", \"abm\", f\"{amro2cute(amro)}\")\n",
    "\n",
    "    for idx_gamma, gamma in enumerate(gammas):\n",
    "        path_to_samples = os.path.join(path_to_save, \"infer_building\", \"individual_observation\", f\"prevalence{idx_gamma}\")\n",
    "        inference       = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "\n",
    "        if os.path.isfile(os.path.join(path_to_samples,  f\"{str(id_run).zfill(3)}sim_post.npz\")):\n",
    "            continue\n",
    "\n",
    "        alpha = 1/120\n",
    "        f0    = lambda θ:       amr_abm(t = 0,\n",
    "                                                        agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "        f       = lambda t, x, θ: amr_abm(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        gamma          = gamma,\n",
    "                                                        beta           = θ[1, :],\n",
    "                                                        alpha          = alpha,\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        ward2size      = ward2size,\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        g = lambda t, x, θ: observe_cluster_individual(t = t,\n",
    "                                                        agents_state   = x,\n",
    "                                                        rho            = θ[0, :],\n",
    "                                                        movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                        model_settings = model_settings)\n",
    "\n",
    "        θ    = inference[\"posterior\"].mean(-2)[:, :, -1]\n",
    "        ysim = simulate_abm(f, f0, g, θ, model_settings)\n",
    "        np.savez_compressed(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}sim_post.npz\"),\n",
    "                                        y         = ysim,\n",
    "                                        posterior = θ,\n",
    "                                        gamma     = gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates as mdates\n",
    "from utils import create_df_response\n",
    "from utils_local import plot_utils\n",
    "\n",
    "\n",
    "def format_axis(ax, week=False):\n",
    "    ax.tick_params(which='both', axis='x', labelrotation=90)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%y'))\n",
    "    if week:\n",
    "        ax.xaxis.set_minor_locator(mdates.WeekdayLocator())\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "id2building    = {v: k for k, v in building2id.items()}\n",
    "id2building[5] = \"Rest\"\n",
    "\n",
    "fig     = plt.figure(constrained_layout=True, figsize=(10.5, 7.2))\n",
    "subfigs = fig.subfigures(2, 1, hspace=0.1, wspace=0.2, height_ratios=[0.35, 0.65])\n",
    "\n",
    "# hospital level\n",
    "ax1      = subfigs[0].subplots(1, 1, sharex=\"col\")\n",
    "\n",
    "yi_df = create_df_response(ysim[:, :, :].sum(1), time=len(model_settings[\"dates_simulation\"]), dates=model_settings[\"dates_simulation\"])\n",
    "yi_df = yi_df.drop(columns=[\"type\"]).resample(\"W-Sun\").sum()\n",
    "\n",
    "ax1.scatter(if_settings[\"assimilation_dates\"], obs_df[[f\"y{i+1}\" for i in range(model_settings[\"k\"])]].sum(axis=1),\n",
    "                ec=None, fc=\"red\", label=\"Data\", s=30)\n",
    "\n",
    "ax1.plot(yi_df.index, yi_df[\"mean\"], label=\"Median\", color=\"gray\", lw=1)\n",
    "ax1.fill_between(yi_df.index, yi_df[\"low_95\"], yi_df[\"high_95\"], color=\"gray\", alpha=0.2, label=\"95% CI\")\n",
    "ax1.fill_between(yi_df.index, yi_df[\"low_50\"], yi_df[\"high_50\"], color=\"gray\", alpha=0.3, label=\"50% CI\")\n",
    "\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.legend().remove()\n",
    "ax1.set_ylabel(None)\n",
    "\n",
    "ax1.tick_params(which='both', axis='x', labelrotation=0)\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%y'))\n",
    "ax1.text(x = 18286.0, y = 110, s=\"Aggregated\", fontweight = \"bold\")\n",
    "\n",
    "# building level\n",
    "ax2      = subfigs[1].subplots(2, 3, sharex=True, sharey=False)\n",
    "pos2plot = {0:2, 1: 0, 2: 4, 3: 3, 4: 1, 5: 5}\n",
    "\n",
    "for idx_axi, axi, in enumerate(ax2.flatten()):\n",
    "    idx_axi = pos2plot[idx_axi]\n",
    "\n",
    "    yi_df = create_df_response(ysim[:, idx_axi, :], time=len(model_settings[\"dates_simulation\"]), dates=model_settings[\"dates_simulation\"])\n",
    "    yi_df = yi_df.drop(columns=[\"type\"]).resample(\"W-Sun\").sum()\n",
    "\n",
    "    axi.scatter(if_settings[\"assimilation_dates\"], obs_df[f\"y{idx_axi+1}\"],\n",
    "                        ec=None, fc=\"red\", label=\"Data\", s=15)\n",
    "    axi.plot(yi_df.index, yi_df[\"mean\"], label=\"Mean\", color=\"gray\", lw=1)\n",
    "    axi.fill_between(yi_df.index, yi_df[\"low_95\"], yi_df[\"high_95\"], color=\"gray\", alpha=0.2, label=\"95% CI\")\n",
    "    axi.fill_between(yi_df.index, yi_df[\"low_50\"], yi_df[\"high_50\"], color=\"gray\", alpha=0.3, label=\"50% CI\")\n",
    "\n",
    "    axi.tick_params(which='both', axis='x', labelrotation=65)\n",
    "    axi.xaxis.set_major_formatter(mdates.DateFormatter('%m/%y'))\n",
    "    axi.spines['right'].set_visible(False)\n",
    "    axi.spines['top'].set_visible(False)\n",
    "    axi.legend().remove()\n",
    "    axi.set_ylabel(None)\n",
    "    axi.set_xlabel(None)\n",
    "    axi.text(x = 18296.0, y = yi_df[\"high_95\"].max(),\n",
    "                s=id2building[idx_axi].split(\"-\")[0], fontweight = \"bold\")\n",
    "\n",
    "#ax2[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0.0, 1.25), ncol=4, frameon=False)\n",
    "for i in range(3):\n",
    "    ax2[-1, i].set_xlabel(\"Date\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
