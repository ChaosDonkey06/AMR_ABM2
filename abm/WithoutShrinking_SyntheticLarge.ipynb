{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir          = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]\n",
    "\n",
    "from abm_utils import empirical_prevalence, simulate_abm, create_obs_infer\n",
    "from utils_local.misc import amro2title, amro2cute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_simulation = pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\")\n",
    "\n",
    "movement_df                  = pd.read_csv(os.path.join(data_db_dir, \"long_files_8_25_2021\", 'patient_movement_2022-Nov.csv'), parse_dates=['date']).drop_duplicates(subset=[\"date\", \"mrn\"], keep=\"first\")\n",
    "movement_df[\"ward_total\"]    = movement_df.apply(lambda x: x[\"ward\"]+\"-\"+x[\"building\"]+\"-\"+x[\"place\"], axis=1)\n",
    "movement_df                  = movement_df[movement_df[\"date\"].isin(dates_simulation)]\n",
    "\n",
    "mrd2id                       = {mrn: id for id, mrn in enumerate(movement_df.mrn.unique())}\n",
    "ward2id                      = {ward_name: id for id, ward_name in enumerate(np.sort(movement_df.ward_total.unique()))}\n",
    "\n",
    "movement_df[\"mrn_id\"]        = movement_df.mrn.map(mrd2id)\n",
    "movement_df[\"ward_id\"]       = movement_df.ward_total.map(ward2id)\n",
    "\n",
    "ward_size_df                 = movement_df.reset_index()\n",
    "ward_size_df[\"ward_id\"]      = ward_size_df[\"ward_total\"].apply(lambda x: ward2id[x])\n",
    "ward_size_df[\"num_patients\"] = 1\n",
    "ward_size_df                 = ward_size_df.groupby([\"date\", \"ward\", \"ward_id\"]).sum()[[\"num_patients\"]].reset_index().drop(columns=[\"date\"])\n",
    "ward_size_df                 = ward_size_df.groupby([\"ward\", \"ward_id\"]).mean().reset_index().sort_values(by=\"num_patients\")\n",
    "ward2size                    = {r.ward_id: r.num_patients for idx_r, r in ward_size_df.iterrows()}\n",
    "\n",
    "id2ward                      = dict((v, k) for k, v in ward2id.items())\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia',\n",
    "                        'Milstein Hospital-Columbia', 'Mschony-Chony',\n",
    "                        'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names                   = np.sort(list(movement_df.ward_total.unique()))\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "\n",
    "###-###-###-###-###-###-###-###-###-###-###-###\n",
    "\n",
    "selected_buildings     = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id            = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "wardid2buildingid      = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n",
    "movement_df[\"cluster\"] = movement_df.ward_id.map(wardid2buildingid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas_search = [0.25, 0.5, 0.75, 0.15]\n",
    "betas_search  = [0.01, 0.05, 0.1]\n",
    "rho_search    = [1/100, 5/100, 10/100, 18/100]\n",
    "\n",
    "idx_sce = 0\n",
    "scenarios_large_df = pd.DataFrame(columns=[\"scenario\", \"gamma\", \"beta\", \"rho\"])\n",
    "for g in gammas_search:\n",
    "    for b in betas_search:\n",
    "        for r in rho_search:\n",
    "            scenarios_large_df = scenarios_large_df.append({\"scenario\": f\"scenario{int(idx_sce+1)}\", \"gamma\": g, \"beta\": b, \"rho\": r}, ignore_index=True)\n",
    "            idx_sce += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import amr_abm, observe_cluster_individual\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "model_settings   = {\n",
    "                    \"m\"                 : 200,\n",
    "                    \"p\"                 : 2,\n",
    "                    \"n\"                 : movement_df.mrn_id.unique().shape[0],\n",
    "                    \"k\"                 : movement_df.cluster.unique().shape[0],\n",
    "                    \"dates\"             : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"dates_simulation\"  : pd.date_range(start=\"2020-02-01\", end=\"2021-02-28\", freq=\"D\"),\n",
    "                    \"T\"                 : len(dates_simulation),  # time to run\n",
    "                    \"num_build\"         : len(np.unique(list(wardid2buildingid.values()))),\n",
    "                    \"k\"                 : len(np.unique(list(wardid2buildingid.values())))# observing at the building aggregation\n",
    "                }\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "\n",
    "id_run                            = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_local.misc import amro2title, amro2cute\n",
    "from abm_utils import run_amro_synthetic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx_row, row in scenarios_large_df.iterrows():\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"])\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "    gamma = row[\"gamma\"]\n",
    "\n",
    "    print(f\"\\t Synthetic {idx_row+1}/{len(scenarios_large_df)}\", end=\"\\r\")\n",
    "    model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "    if_settings[\"adjust_state_space\"] = False\n",
    "    if_settings[\"shrink_variance\"]    = False\n",
    "\n",
    "    path_to_samples = os.path.join(path_to_save, \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "    os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "    if os.path.isfile(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\")):\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "\n",
    "    alpha               = 1/120\n",
    "    init_state          = lambda θ: amr_abm(t = 0,\n",
    "                                            agents_state   = np.zeros((model_settings[\"n\"], model_settings[\"m\"])),\n",
    "                                            gamma          = gamma,\n",
    "                                            beta           = θ[1, :],\n",
    "                                            alpha          = alpha,\n",
    "                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[0]],\n",
    "                                            ward2size      = ward2size,\n",
    "                                            model_settings = model_settings)\n",
    "\n",
    "    process       = lambda t, x, θ: amr_abm(t = t,\n",
    "                                            agents_state   = x,\n",
    "                                            gamma          = gamma,\n",
    "                                            beta           = θ[1, :],\n",
    "                                            alpha          = alpha,\n",
    "                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                            ward2size      = ward2size,\n",
    "                                            model_settings = model_settings)\n",
    "\n",
    "    obs_model = lambda t, x, θ: observe_cluster_individual(t = t,\n",
    "                                                            agents_state   = x,\n",
    "                                                            rho            = θ[0, :],\n",
    "                                                            movement       = movement_df[movement_df[\"date\"]==dates_simulation[t]],\n",
    "                                                            model_settings = model_settings)\n",
    "\n",
    "    run_amro_synthetic(f               = process,\n",
    "                        f0             = init_state,\n",
    "                        g              = obs_model,\n",
    "                        fsim           = simulate_abm,\n",
    "                        model_settings = model_settings,\n",
    "                        if_settings    = if_settings,\n",
    "                        id_run         = id_run,\n",
    "                        path_to_save   = path_to_samples,\n",
    "                        use_mean       = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "\n",
    "gammas = [0.25, 0.50]\n",
    "\n",
    "path_to_save_fig = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", \"figures\")\n",
    "id_run           = 0\n",
    "\n",
    "for gamma in gammas:\n",
    "    sce_df = scenarios_large_df[scenarios_large_df.gamma==gamma]\n",
    "    i_ax   = 0\n",
    "    fig, axes = plt.subplots(len(sce_df), 2, figsize=(10, 14.2), sharex=True, sharey=\"col\")\n",
    "    for idx_row, row in sce_df.iterrows():\n",
    "\n",
    "        path_to_samples   = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"], \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "        samples_inference = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "\n",
    "        θpost = samples_inference[\"posterior\"]\n",
    "        θmle  = samples_inference[\"mle\"]\n",
    "        Nif   = θpost.shape[-1]\n",
    "        θpost = θpost[:, :, :, :].mean(-2)\n",
    "\n",
    "        ρ_df = create_df_response(θpost[0, :, :].T, time=Nif)\n",
    "        β_df = create_df_response(θpost[1, :, :].T, time=Nif)\n",
    "\n",
    "        p_dfs       = [ρ_df, β_df]\n",
    "        param_label = [\"ρ\", \"β\"]\n",
    "        p_truth     = [row.rho, row.beta]\n",
    "\n",
    "        parameters_range  = np.array([[0.01, 20/100], [0, 0.15]])\n",
    "        convergence_plot(θmle, p_dfs, parameters_range, param_label, ax=axes[i_ax, :], fig=fig, param_truth=p_truth)\n",
    "        axes[i_ax, 0].legend().remove(); axes[i_ax, 1].legend().remove()\n",
    "        axes[i_ax, 1].set_xlabel(None)\n",
    "        axes[i_ax, 0].spines['right'].set_visible(False)\n",
    "        axes[i_ax, 0].spines['top'].set_visible(False)\n",
    "        axes[i_ax, 0].text(x=0.1, y=0.18,\n",
    "                        s=f\"Scenario {idx_row+1} \\n\"+r\"$\\gamma=${:0.0f}%, $\\rho=${:0.1f}%, $\\beta=${:0.2f}\".format(row.gamma*100, row.rho*100, row.beta),\n",
    "                            weight='bold',\n",
    "                            color=\"indigo\")\n",
    "        i_ax += 1\n",
    "\n",
    "    axes[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0.0, 1.85), ncol=4)\n",
    "    axes[-1, 0].set_xlabel(\"Iteration\")\n",
    "    axes[-1, 1].set_xlabel(\"Iteration\")\n",
    "\n",
    "    fig.savefig(os.path.join(path_to_save_fig, \"convergence_plots_gamma{}.png\".format(gamma)), dpi=300, bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_df = pd.DataFrame()\n",
    "\n",
    "for idx_row, row in scenarios_large_df.iterrows():\n",
    "\n",
    "    path_to_samples = os.path.join(results2_dir, \"synthetic_inferences\", \"abm\", \"large_search\", row[\"scenario\"], \"infer_building\", f\"scenario{idx_row+1}\")\n",
    "    inference       = np.load(os.path.join(path_to_samples, f\"{str(id_run).zfill(3)}posterior.npz\"))\n",
    "\n",
    "    θmle      = inference[\"mle\"]\n",
    "    θpost     = inference[\"posterior\"]\n",
    "    y_sim     = inference[\"observations\"]\n",
    "    θtruth    = inference[\"teta_truth\"]\n",
    "    idx_infer = inference[\"idx_infer\"]\n",
    "    Nif       = θpost.shape[-1]\n",
    "\n",
    "    ρ_post = θpost[0, :, :, :].mean(-2).flatten()\n",
    "    β_post = θpost[1, :, :, :].mean(-2).flatten()\n",
    "\n",
    "    post_df                = pd.DataFrame(columns=[\"value\", \"param\", \"ens_id\", \"if_iter\"])\n",
    "    post_df[\"value\"]       = np.concatenate([ρ_post, β_post])\n",
    "    post_df[\"value_truth\"] = np.concatenate([θtruth[0, 0]*np.ones_like(ρ_post), θtruth[1, 0]*np.ones_like(β_post)])\n",
    "\n",
    "    post_df[\"param\"]    = [\"ρ\"] * len(ρ_post) + [\"β\"] * len(β_post)\n",
    "    post_df[\"if_iter\"]  = flatten_list([list(range(Nif)) * model_settings[\"m\"] ] * 2 )\n",
    "    post_df[\"ens_id\"]   = flatten_list([[i] * Nif for i in range( model_settings[\"m\"])] * 2)\n",
    "    post_df[\"gamma\"]    = row.gamma\n",
    "    post_df[\"scenario\"] = idx_row\n",
    "\n",
    "    posterior_df        = pd.concat([posterior_df, post_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmtick\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m v_df \u001b[38;5;241m=\u001b[39m \u001b[43mposterior_df\u001b[49m[posterior_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m Nif\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_gamma, gamma \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]):\n\u001b[1;32m      8\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15.2\u001b[39m, \u001b[38;5;241m12.2\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior_df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "v_df = posterior_df[posterior_df[\"if_iter\"] == Nif-1]\n",
    "\n",
    "for idx_gamma, gamma in enumerate([0.25, 0.5]):\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15.2, 12.2), sharey=False, sharex=False)\n",
    "    for idx_scenario, ax in enumerate(axes.flatten()):\n",
    "\n",
    "        p_df             = v_df[v_df.gamma==gamma]\n",
    "        p_df             = p_df[p_df[\"scenario\"] == p_df[\"scenario\"].unique()[idx_scenario]]\n",
    "        rho_df           = p_df[p_df[\"param\"] == \"ρ\"].reset_index(drop=True)\n",
    "        beta_df          = p_df[p_df[\"param\"] == \"β\"].reset_index(drop=True)\n",
    "        rho_df[\"value\"]  = rho_df[\"value\"] * 100\n",
    "\n",
    "        sns.kdeplot(ax    = ax,\n",
    "                    x     = rho_df[\"value\"],\n",
    "                    y     = beta_df[\"value\"],\n",
    "                    cmap  = \"Reds\",\n",
    "                    fill  = True,  thresh=0)\n",
    "        ax.scatter(x          = rho_df[\"value\"],\n",
    "                    y         = beta_df[\"value\"],\n",
    "                    facecolor = \"mediumpurple\",\n",
    "                    edgecolor = \"k\", alpha=0.2, s=10)\n",
    "\n",
    "        ax.axhline(y=beta_df[\"value_truth\"].drop_duplicates().values[0], color=\"k\", lw=1, ls=\"--\")\n",
    "        ax.axvline(x=rho_df[\"value_truth\"].drop_duplicates().values[0] * 100, color=\"k\", lw=1, ls=\"--\")\n",
    "\n",
    "        ax.scatter(x          = rho_df[\"value_truth\"].drop_duplicates()*100,\n",
    "                    y         = beta_df[\"value_truth\"].drop_duplicates(),\n",
    "                    marker    = \"x\",\n",
    "                    facecolor = \"yellow\",\n",
    "                    lw        = 3,\n",
    "                    s         = 100)\n",
    "\n",
    "        ax.text(x = 0.05,\n",
    "                y = 0.9,\n",
    "                s = \"Truth\\n\"+r\"$\\rho=${:0.0f}%\".format(rho_df[\"value_truth\"].drop_duplicates().values[0]*100,) +\"\\n\"+\n",
    "                        r\"$\\beta=${:0.2f}\".format(beta_df[\"value_truth\"].drop_duplicates().values[0]),\n",
    "                weight='bold', color=\"indigo\", transform=axi.transAxes)\n",
    "\n",
    "\n",
    "        #ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "        ax.set_title(\"Scenario {}\".format(p_df.scenario.unique()[0]+1))\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(None)\n",
    "\n",
    "    fig.suptitle(\"Posterior joint distribution $\\gamma=${:0.0f}%\".format(gamma*100), x=0.5, y=1.05)\n",
    "\n",
    "    axes[0, 0].set_ylabel(r\"$\\beta$\")\n",
    "    axes[1, 0].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[-1, i].set_xlabel(r\"$\\rho$ (%)\")\n",
    "\n",
    "    for axi in axes.flatten():\n",
    "        axi.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.3f'))\n",
    "        axi.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(os.path.join(path_to_save_fig, \"joint_distribution_gamma{}.png\".format(gamma)), dpi=300, bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_local import plot_utils\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "v_df = posterior_df[posterior_df[\"if_iter\"] == Nif-1]\n",
    "\n",
    "for idx_gamma, gamma in enumerate([0.25, 0.5]):\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15.2, 12.2), sharey=True, sharex=True)\n",
    "    for idx_scenario, ax in enumerate(axes.flatten()):\n",
    "        p_df             = v_df[v_df.gamma==gamma]\n",
    "        p_df             = p_df[p_df[\"scenario\"] == p_df[\"scenario\"].unique()[idx_scenario]]\n",
    "        rho_df           = p_df[p_df[\"param\"] == \"ρ\"].reset_index(drop=True)\n",
    "        beta_df          = p_df[p_df[\"param\"] == \"β\"].reset_index(drop=True)\n",
    "        rho_df[\"value\"]  = rho_df[\"value\"] * 100\n",
    "\n",
    "        sns.kdeplot(ax    = ax,\n",
    "                    x     = list(rho_df[\"value\"].values) + [0, 20],\n",
    "                    y     = list(beta_df[\"value\"])       + [-0.02, 0.22],\n",
    "                    cmap  = \"Reds\",\n",
    "                    fill  = True,  thresh=0)\n",
    "\n",
    "        ax.scatter(x          = rho_df[\"value\"],\n",
    "                    y         = beta_df[\"value\"],\n",
    "                    facecolor = \"mediumpurple\",\n",
    "                    edgecolor = None, alpha=0.2, s=8)\n",
    "\n",
    "        ax.axhline(y=beta_df[\"value_truth\"].drop_duplicates().values[0], color=\"k\", lw=1, ls=\"--\")\n",
    "        ax.axvline(x=rho_df[\"value_truth\"].drop_duplicates().values[0] * 100, color=\"k\", lw=1, ls=\"--\")\n",
    "\n",
    "        ax.scatter(x          = rho_df[\"value_truth\"].drop_duplicates()*100,\n",
    "                    y         = beta_df[\"value_truth\"].drop_duplicates(),\n",
    "                    marker    = \"x\",\n",
    "                    facecolor = \"yellow\",\n",
    "                    lw        = 3,\n",
    "                    s         = 50)\n",
    "\n",
    "        ax.text(x = 1.5,\n",
    "                y = 0.135,\n",
    "                s = \"Truth\\n\"+r\" $\\rho=${:0.0f}%\".format(rho_df[\"value_truth\"].drop_duplicates().values[0]*100,) +\"\\n\"+\n",
    "                        r\" $\\beta=${:0.2f}\".format(beta_df[\"value_truth\"].drop_duplicates().values[0]),\n",
    "                weight='bold', color=\"indigo\")\n",
    "\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.set_ylim((0, 0.2))\n",
    "        ax.set_xlim((0, 21))\n",
    "\n",
    "        #ax.xaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "        ax.set_title(\"Scenario {}\".format(p_df.scenario.unique()[0]+1))\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(None)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "    axes[0, 0].set_ylabel(r\"$\\beta$\")\n",
    "    axes[1, 0].set_ylabel(r\"$\\beta$\")\n",
    "    axes[2, 0].set_ylabel(r\"$\\beta$\")\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[-1, i].set_xlabel(r\"$\\rho$ (%)\")\n",
    "\n",
    "    for axi in axes.flatten():\n",
    "        axi.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.3f'))\n",
    "        axi.xaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "\n",
    "    fig.suptitle(\"Posterior joint distribution $\\gamma=${:0.0f}%\".format(gamma*100), x=0.5, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(path_to_save_fig, \"joint_distribution_gamma{}_2.png\".format(gamma)), dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
