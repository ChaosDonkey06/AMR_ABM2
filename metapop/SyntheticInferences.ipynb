{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def flatten_list(list_array):\n",
    "    return list(itertools.chain(*list_array))\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0,\"../pompjax/pompjax/\")\n",
    "\n",
    "from global_config import config\n",
    "\n",
    "results_dir           = config.get_property('results_dir')\n",
    "results2_dir           = config.get_property('results2_dir')\n",
    "\n",
    "data_dir              = config.get_property('data_dir')\n",
    "paper_dir             = config.get_property('paper_dir')\n",
    "data_db_dir           = config.get_property('data_db_dir')\n",
    "feb_hosp_records_path = os.path.join(data_db_dir, 'long_files_8_25_2021')\n",
    "path_to_save          = os.path.join(results_dir, \"real_testing\", \"community\")\n",
    "\n",
    "COLOR_LIST1           = [\"#F8AFA8\", \"#FDDDA0\", \"#F5CDB4\", \"#74A089\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data_metapop import create_population_data, create_time_transfers\n",
    "\n",
    "path_to_ward_counts = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"counts_ward.csv\" )\n",
    "path_to_ward_transf = os.path.join(data_db_dir, \"long_files_8_25_2021\", \"transfers_ward.csv\" )\n",
    "\n",
    "A_df, D_df, H_df, tests_df, Hmean_df = create_population_data(path_to_ward_counts)\n",
    "\n",
    "num_wards  = len(Hmean_df)\n",
    "ward_names = list(Hmean_df.index)\n",
    "M_df       = create_time_transfers(path_to_ward_transf, num_wards=num_wards, ward_names=ward_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we want to choose synthetic scenarios that overall reproduce the synthetic observations, so we are going to use the stuff above (in the GridSearch) to sample from the parameter space and create the synthetic scenarios randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_buildings = ['Allen Hospital-Allen', 'Harkness Pavilion-Columbia', 'Milstein Hospital-Columbia', 'Mschony-Chony', 'Presbyterian Hospital-Columbia']\n",
    "building2id        = {selected_buildings[i]: i for i in range(len(selected_buildings))}\n",
    "\n",
    "def building2observation(building):\n",
    "    if building in selected_buildings:\n",
    "        return building2id[building]\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "ward_names_df                = pd.DataFrame(ward_names, columns=[\"ward\"])\n",
    "ward_names_df[\"building\"]    = ward_names_df[\"ward\"].apply(lambda x: \"-\".join(x.split(\"-\")[1:]))\n",
    "ward_names_df[\"buidling_id\"] = ward_names_df[\"building\"].apply(lambda x: building2observation(x) )\n",
    "ward_names_df[\"ward_id\"]     = ward_names_df.apply(lambda x: np.where(ward_names_df.ward == x.ward)[0][0], axis=1)\n",
    "wardid2buildingid            = {row.ward_id: row.buidling_id for i, row in ward_names_df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import process_metapop, observe_metapop_cluster, init_metapop, simulate_metapop, simulate_metapop_observations\n",
    "from misc import amro2cute\n",
    "\n",
    "delta = 1/120  # decolonization rate\n",
    "A     = A_df.to_numpy()\n",
    "D     = D_df.to_numpy()\n",
    "H     = H_df.to_numpy()\n",
    "M     = M_df\n",
    "tests = tests_df.to_numpy()\n",
    "\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def return_score_cutoff(score, cut_off_prob=0.05):\n",
    "    freq, score = np.histogram(score, bins=100, density=True)\n",
    "    freq_cum    = np.cumsum(freq); freq_cum = freq_cum/freq_cum[-1]\n",
    "    score       = score[1:]\n",
    "    f_cum       = UnivariateSpline(score, freq_cum, s=0.001)\n",
    "    sc_range    = np.linspace(np.min(score), np.max(score), 1000)\n",
    "    score_cut   = sc_range[np.argmin(np.abs(f_cum(sc_range) * 100 - cut_off_prob*100))]\n",
    "    return score_cut\n",
    "\n",
    "def sample_scenarios(path_to_grid_search, cut_off=10/100):\n",
    "    gs_df        = pd.read_csv( path_to_grid_search )\n",
    "    sc_cutoff    = return_score_cutoff(gs_df.crps, cut_off_prob=cut_off)\n",
    "    gs_df        = gs_df[gs_df.crps <= sc_cutoff].reset_index(drop=True)\n",
    "    scenarios_df = gs_df.copy()\n",
    "    scenarios_df = scenarios_df.sample(n=10); scenarios_df = scenarios_df[[\"rho\", \"beta\", \"crps\", \"calibration_score\"]].reset_index(drop=True)\n",
    "    return scenarios_df\n",
    "\n",
    "def empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\"):\n",
    "    amro_prev_df = pd.read_csv(path_to_prev)\n",
    "    gamma        = amro_prev_df[amro_prev_df.amro==amro][\"prevalence_mean1\"].values[0]/100\n",
    "    return gamma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inferences not adjusting the state space, as with the ABM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_plots import convergence_plot\n",
    "from utils import create_df_response\n",
    "from ifeakf import ifeakf\n",
    "\n",
    "\n",
    "def create_obs_infer(obs_sim, idx_infer, dates, model_settings, resample=\"W-Sun\"):\n",
    "\n",
    "    # obs_sim \\in R^{[k x T x m]} as required by pompjax\n",
    "    infer_df = pd.DataFrame(index=dates)\n",
    "    for i in range(model_settings[\"k\"]) :\n",
    "        infer_df['y'+str(i+1)]   = obs_sim[i, :, idx_infer]\n",
    "        infer_df['oev'+str(i+1)] = 1 +(0.2 * infer_df['y'+str(i+1)].values)**2\n",
    "    infer_df                     = infer_df.resample(resample).sum()\n",
    "    infer_df.index.values[-1]    = model_settings[\"dates\"][-1]\n",
    "    return infer_df\n",
    "\n",
    "def run_amro_synthetic(f, f0, g, fsim, model_settings, if_settings, id_run=0, path_to_save=None):\n",
    "    dates        = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "\n",
    "    θtruth       = np.array([model_settings[\"param_truth\"]]).T * np.ones((model_settings[\"p\"], model_settings[\"m\"]))\n",
    "    x_sim, y_sim = fsim(process_model           = f,\n",
    "                            observational_model = g,\n",
    "                            init_state          = f0,\n",
    "                            θsim                = θtruth,\n",
    "                            model_settings      = model_settings)\n",
    "\n",
    "    idx_infer = np.random.randint(model_settings[\"m\"])\n",
    "    obs_df    = create_obs_infer(y_sim.transpose(1, 0, 2), idx_infer, dates, model_settings, resample=\"W-Sun\")\n",
    "\n",
    "    ρmin              = 0.01 # test sensitivity minimum\n",
    "    ρmax              = 0.2  # test sensitivity maximum\n",
    "    βmin              = 0.00 # transmission rate minimum\n",
    "    βmax              = 0.5  # transmission rate maximum\n",
    "\n",
    "    max_total_pop     = np.max(H.sum(axis=0))\n",
    "    state_space_range = np.array([0, max_total_pop])\n",
    "    parameters_range  = np.array([[ρmin, ρmax],    [βmin, βmax]])\n",
    "    σ_perturb         = np.array([(ρmax - ρmin)/4, (βmax - βmin)/4]) # (i hve the gut feeling that 0.25 is too large)\n",
    "\n",
    "    θmle, θpost = ifeakf(process_model                = f,\n",
    "                            state_space_initial_guess = f0,\n",
    "                            observational_model       = g,\n",
    "                            observations_df           = obs_df,\n",
    "                            parameters_range          = parameters_range,\n",
    "                            state_space_range         = state_space_range,\n",
    "                            model_settings            = model_settings,\n",
    "                            if_settings               = if_settings,\n",
    "                            perturbation              = σ_perturb)\n",
    "\n",
    "    np.savez_compressed(os.path.join(path_to_save, f\"{str(id_run).zfill(3)}posterior.npz\"),\n",
    "                                    mle           = θmle,\n",
    "                                    posterior     = θpost,\n",
    "                                    state_space   = x_sim,\n",
    "                                    observations  = y_sim,\n",
    "                                    teta_truth    = θtruth,\n",
    "                                    idx_infer     = idx_infer)\n",
    "\n",
    "    ρ_df = create_df_response(θpost[0, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "    β_df = create_df_response(θpost[1, :, :, :].mean(-2).T, time=if_settings[\"Nif\"])\n",
    "\n",
    "    p_dfs             = [ρ_df, β_df]\n",
    "    param_label       = [\"ρ\", \"β\"]\n",
    "    parameters_range  = np.array([[ρmin, ρmax], [βmin, βmax]])\n",
    "    convergence_plot(θmle, p_dfs, parameters_range, param_label, param_truth=list(θtruth[:, 0]),\n",
    "                        path_to_save=os.path.join(path_to_save, f\"{str(id_run).zfill(3)}convergence.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create scenarios ####\n",
    "amro_search  = ['ESCHERICHIA COLI', 'KLEBSIELLA PNEUMONIAE',  'PSEUDOMONAS AERUGINOSA',\n",
    "                'METHICILLIN-SUSCEPTIBLE STAPHYLOCOCCUS AUREUS',\n",
    "                \"STAPHYLOCOCCUS EPIDERMIDIS\", 'ENTEROCOCCUS FAECALIS', 'ENTEROCOCCUS FAECIUM']\n",
    "\n",
    "path_to_scenarios         = os.path.join(results2_dir, \"synthetic_inferences\", \"metapopulation\")\n",
    "for amro in amro_search:\n",
    "    path_to_grid_search           = os.path.join(results2_dir, \"grid_search\", \"metapopulation\", f\"{amro2cute(amro)}.csv\")\n",
    "    os.makedirs(os.path.join(path_to_scenarios, f\"{amro2cute(amro)}\"), exist_ok=True)\n",
    "\n",
    "    scenarios_df                  = sample_scenarios(path_to_grid_search, cut_off=5/100)\n",
    "    scenarios_df.to_csv(os.path.join(path_to_scenarios, f\"{amro2cute(amro)}\", \"scenarios.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import amro2title\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],       # importation and transmission rate\n",
    "    \"p\"           : 2,                # number of parameters\n",
    "    \"dt\"          : 1,                # time step\n",
    "    \"m\"           : 300,              # number of ensembles\n",
    "    \"stochastic\"  : True              # is stochastic\n",
    "    }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "num_pop          = num_wards\n",
    "\n",
    "model_settings[\"n\"]           = 3 * num_pop            # number of state variables / dimension of the state space\n",
    "model_settings[\"T\"]           = len(dates_simulation)  # time to run\n",
    "model_settings[\"num_pop\"]     = num_pop\n",
    "model_settings[\"dates\"]       = dates_simulation\n",
    "model_settings[\"num_build\"]   = len(np.unique(list(wardid2buildingid.values())))\n",
    "model_settings[\"k\"]           = model_settings[\"num_build\"] # observing at the building aggregation\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"metapopulation\", f\"{amro2cute(amro)}\")\n",
    "    scenarios_df = pd.read_csv(os.path.join(path_to_save, \"scenarios.csv\"))\n",
    "\n",
    "    gamma        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "        print(f\"\\t Synthetic {idx_row+1}/{len(scenarios_df)}\")\n",
    "\n",
    "        model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "        if_settings[\"adjust_state_space\"] = False\n",
    "\n",
    "        init_state  = lambda θ:  init_metapop(N0               = H[:, 0],\n",
    "                                                c0             = gamma,\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "        process  = lambda t, x, θ: process_metapop(t, x,\n",
    "                                                    gamma = gamma * np.ones(model_settings[\"m\"]),\n",
    "                                                    beta  = θ[1, :],\n",
    "                                                    delta = delta,\n",
    "                                                    Nmean = np.expand_dims(Hmean_df, -1),\n",
    "                                                    N     = H[:, [t]],\n",
    "                                                    A     = A[:, [t]],\n",
    "                                                    D     = D[:, [t]],\n",
    "                                                    M     = M[:, :, t])\n",
    "\n",
    "        obs_model = lambda t, x, θ: observe_metapop_cluster(t, x,\n",
    "                                                        rho            = θ[0, :],\n",
    "                                                        N              = H[:, [t]],\n",
    "                                                        num_tests      = tests[:, [t]],\n",
    "                                                        model_settings = model_settings,\n",
    "                                                        ward2cluster   = wardid2buildingid)\n",
    "\n",
    "        path_to_samples = os.path.join(path_to_save, \"no_adjust_state_space\", f\"scenario{idx_row+1}\")\n",
    "        os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "        run_amro_synthetic(f               = process,\n",
    "                            f0             = init_state,\n",
    "                            g              = obs_model,\n",
    "                            fsim           = simulate_metapop,\n",
    "                            model_settings = model_settings,\n",
    "                            if_settings    = if_settings, id_run=0,\n",
    "                            path_to_save   = path_to_samples\n",
    "                            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferences adjusting the state space\n",
    "\n",
    "the problem is that pompjax asssume the state space is a vector $x\\in R^{n \\times m}$, and we putted the number of populations of the meta in the second axis such that $x\\in R^{3 \\times p \\times m }$, and $n=3 \\times p$. $p:=$ number of populations.\n",
    "\n",
    "So we need to change the process model to handle this, I think it could be done easily just adding a np.reshape(-1, m), but we'll see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import binomial_transition, poisson_transition, check_state_space\n",
    "\n",
    "def process_metapop2(t, x, gamma, beta, delta, Nmean, N, A, D, M, model_settings=None):\n",
    "    \"\"\" Susceptible - Colonized meta-population model\n",
    "\n",
    "    Args:\n",
    "        x[t]  : state space\n",
    "        gamma : importation rate\n",
    "        beta  : transmission rate\n",
    "        delta : decolonization rate\n",
    "        A     : Admitted\n",
    "        D     : Discharged\n",
    "        M     : Movements matrix\n",
    "\n",
    "    Returns:\n",
    "        x[t+1]: State space in t+1.\n",
    "    \"\"\"\n",
    "\n",
    "    n       = model_settings[\"n\"]\n",
    "    num_pop = model_settings[\"num_pop\"]\n",
    "    m       = model_settings[\"m\"]\n",
    "\n",
    "    x = np.reshape(x, (int(n/num_pop), num_pop, m))\n",
    "    C = x[0, :, :]\n",
    "    S = np.clip(N - C, 0, N)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.clip(np.nan_to_num(C/N), 0, 1)\n",
    "\n",
    "    λ = beta * C / Nmean # force of infection\n",
    "\n",
    "    # moving out and in colonized\n",
    "    Cout  = binomial_transition(list(np.sum(M, axis=1, keepdims=True)), c)\n",
    "    Cin   = M.T @ c\n",
    "\n",
    "    a2c  = binomial_transition(list(A), gamma) # people admitted colonized.\n",
    "    c2d  = binomial_transition(list(D), c)     # discharged colonized\n",
    "\n",
    "    s2c  = poisson_transition(S, λ)     # new colonized\n",
    "    c2s  = poisson_transition(C, delta) # decolonizations\n",
    "\n",
    "    C    = C + a2c - c2d + s2c + c2s + Cin - Cout\n",
    "    C    = np.clip(C, 0, N)\n",
    "    x    = check_state_space(np.array([C, a2c, s2c]))\n",
    "\n",
    "    return np.reshape(x, (n, m))\n",
    "\n",
    "def init_metapop2(N0, c0, model_settings):\n",
    "    \"\"\" Initial conditions model.\n",
    "        Args:\n",
    "            N0 (int):    Initial size of populations.\n",
    "            c0 (int):    Initial fraction of carriers.\n",
    "        Returns:\n",
    "            x0 (np.array): Initial conditions of the state space.\n",
    "    \"\"\"\n",
    "    m       = model_settings[\"m\"]\n",
    "    num_pop = model_settings[\"num_pop\"]\n",
    "    n       = model_settings[\"n\"]\n",
    "\n",
    "    N0   = np.expand_dims(N0, -1) * np.ones((num_pop, m))\n",
    "    C0   = c0 * N0\n",
    "    AC   = np.zeros((num_pop, m))\n",
    "    newC = np.zeros((num_pop, m))\n",
    "    x    = np.array([C0, AC, newC])\n",
    "    return np.reshape(x, (n, m))\n",
    "\n",
    "def observe_metapop2(t, x, N, rho, num_tests, model_settings, ward2cluster=None):\n",
    "    \"\"\" Observational model\n",
    "        Args:\n",
    "            t (int):      Time\n",
    "            x (np.array): State space\n",
    "            rho (float):  Observation probability\n",
    "        Returns:\n",
    "            y (np.array): Observed carriers ~ Binomial(C, rho)\n",
    "    \"\"\"\n",
    "\n",
    "    n       = model_settings[\"n\"]\n",
    "    m       = model_settings[\"m\"]\n",
    "    num_pop = model_settings[\"num_pop\"]\n",
    "    k       = model_settings[\"k\"]\n",
    "\n",
    "    x       = np.reshape(x, (int(n/num_pop), num_pop, m))\n",
    "    C       = x[0, :, :]\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        c = np.clip(np.nan_to_num(C/N), 0, 1)\n",
    "\n",
    "    observed_colonized = np.random.binomial(list(num_tests * np.ones((num_pop, m))), rho * c)\n",
    "    # need to resample this to [num_buildings x m] (maybe using the same buildings that rami used)\n",
    "    obs_col_building = np.zeros((k, m))\n",
    "\n",
    "    for i in range(k):\n",
    "        obs_col_building[ward2cluster[i], :] += observed_colonized[i, :]\n",
    "    return obs_col_building\n",
    "\n",
    "\n",
    "def simulate_metapop2(process_model, observational_model, init_state, θsim, model_settings):\n",
    "    \"\"\" Simulate model with initial conditions and parameters\n",
    "        x \\in R^{n/num_pop x num_pop x ms}\n",
    "\n",
    "    Args:\n",
    "        model (function):        Process model\n",
    "        observe (function):      Observational model\n",
    "        initial_x0 (function):   Initial condition guess model.\n",
    "        θ_sim (np.array):        Parameters\n",
    "    \"\"\"\n",
    "    n = model_settings[\"n\"]\n",
    "    k = model_settings[\"k\"]\n",
    "    m = model_settings[\"m\"]\n",
    "    T = model_settings[\"T\"]\n",
    "    num_pop = model_settings[\"num_pop\"]\n",
    "\n",
    "    x_sim = np.full((T, n, m), np.nan)\n",
    "    y_sim = np.full((T, k, m), np.nan)\n",
    "\n",
    "    x0 = init_state(θsim)\n",
    "\n",
    "    if(x0.shape[0] != n/num_pop or x0.shape[2] != m or x0.shape[1] != num_pop) :\n",
    "        print('error in x0 dimensions')\n",
    "\n",
    "    x_sim[0, :, :] = x0\n",
    "    y_sim[0, :, :] = observational_model(0, x0, θsim)\n",
    "\n",
    "    for t in range(1, T):\n",
    "        x_sim[t, :, :] = process_model(t, x_sim[t-1, :, :], θsim)\n",
    "        y_sim[t, :, :] = observational_model(t, x_sim[t, :, :], θsim)\n",
    "\n",
    "    return x_sim, y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import amro2title\n",
    "\n",
    "if_settings = {\n",
    "        \"Nif\"                : 30,          # number of iterations of the IF\n",
    "        \"type_cooling\"       : \"geometric\", # type of cooling schedule\n",
    "        \"shrinkage_factor\"   : 0.9,         # shrinkage factor for the cooling schedule\n",
    "        \"inflation\"          : 1.01         # inflation factor for spreading the variance after the EAKF step\n",
    "        }\n",
    "\n",
    "model_settings = {\n",
    "    \"param_name\"  : [\"ρ\", \"β\"],       # importation and transmission rate\n",
    "    \"p\"           : 2,                # number of parameters\n",
    "    \"dt\"          : 1,                # time step\n",
    "    \"m\"           : 300,              # number of ensembles\n",
    "    \"stochastic\"  : True              # is stochastic\n",
    "    }\n",
    "\n",
    "dates_simulation = pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"D\")\n",
    "num_pop          = num_wards\n",
    "\n",
    "model_settings[\"n\"]           = 3 * num_pop            # number of state variables / dimension of the state space\n",
    "model_settings[\"T\"]           = len(dates_simulation)  # time to run\n",
    "model_settings[\"num_pop\"]     = num_pop\n",
    "model_settings[\"dates\"]       = dates_simulation\n",
    "model_settings[\"num_build\"]   = len(np.unique(list(wardid2buildingid.values())))\n",
    "model_settings[\"k\"]           = model_settings[\"num_build\"] # observing at the building aggregation\n",
    "\n",
    "assim_dates                       = list(pd.date_range(start=pd.to_datetime(\"2020-02-01\"), end=pd.to_datetime(\"2021-02-28\"), freq=\"W-Sun\"))\n",
    "assim_dates[-1]                   = dates_simulation[-1]\n",
    "if_settings[\"assimilation_dates\"] = assim_dates\n",
    "\n",
    "for amro in amro_search:\n",
    "    print(\"Running IF-EAKF for amro: \", amro2title(amro))\n",
    "\n",
    "    path_to_save = os.path.join(results2_dir, \"synthetic_inferences\", \"metapopulation\", f\"{amro2cute(amro)}\")\n",
    "    scenarios_df = pd.read_csv(os.path.join(path_to_save, \"scenarios.csv\"))\n",
    "\n",
    "    gamma        = empirical_prevalence(amro, path_to_prev=\"../data/amro_prevalence.csv\")\n",
    "\n",
    "    for idx_row, row in scenarios_df.iterrows():\n",
    "        print(f\"\\t Synthetic {idx_row+1}/{len(scenarios_df)}\")\n",
    "\n",
    "        model_settings[\"param_truth\"]     = [row[\"rho\"], row[\"beta\"]]\n",
    "        if_settings[\"adjust_state_space\"] = False\n",
    "\n",
    "        init_state  = lambda θ, gamma:  init_metapop2(\n",
    "                                                N0             = H[:, 0],\n",
    "                                                c0             = gamma, # importation rate\n",
    "                                                model_settings = model_settings)\n",
    "\n",
    "        process  = lambda t, x, θ : process_metapop2(t, x,\n",
    "                                                    gamma = gamma * np.ones(model_settings[\"m\"]),\n",
    "                                                    beta  = θ[1, :],\n",
    "                                                    delta = delta,\n",
    "                                                    Nmean = np.expand_dims(Hmean_df, -1),\n",
    "                                                    N     = H[:, [t]],\n",
    "                                                    A     = A[:, [t]],\n",
    "                                                    D     = D[:, [t]],\n",
    "                                                    M     = M[:, :, t],\n",
    "                                                    model_settings=model_settings)\n",
    "\n",
    "        obs_model = lambda t, x, θ: observe_metapop2(t, x,\n",
    "                                                rho            = θ[0, :],\n",
    "                                                N              = H[:, [t]],\n",
    "                                                num_tests      = tests[:, [t]],\n",
    "                                                model_settings = model_settings,\n",
    "                                                ward2cluster   = wardid2buildingid)\n",
    "\n",
    "        path_to_samples = os.path.join(path_to_save, \"adjust_state_space\", f\"scenario{idx_row+1}\")\n",
    "        os.makedirs(path_to_samples, exist_ok=True)\n",
    "\n",
    "        run_amro_synthetic(f               = process,\n",
    "                            f0             = init_state,\n",
    "                            g              = obs_model,\n",
    "                            fsim           = simulate_metapop2,\n",
    "                            model_settings = model_settings,\n",
    "                            if_settings    = if_settings,\n",
    "                            id_run         = 0,\n",
    "                            path_to_save   = path_to_samples\n",
    "                            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (POMPJAX)",
   "language": "python",
   "name": "pompjax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e23b8103492689b0d9748b47018d3861a561878402e3a1e7a565e9dcb2ea3867"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
